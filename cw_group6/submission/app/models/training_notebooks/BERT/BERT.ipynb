{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset # Import dataset import function for hugging face\n",
    "dataset_dict:DatasetDict = load_dataset(\"surrey-nlp/PLOD-CW\") # import the coursework dataset from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dataset_dict[\"train\"]\n",
    "test_dict = dataset_dict[\"test\"]\n",
    "validation_dict = dataset_dict[\"validation\"]\n",
    "\n",
    "train_tokens = [row[\"tokens\"] for row in train_dict]\n",
    "train_pos_tags = [row[\"ner_tags\"] for row in train_dict]\n",
    "train_ner_tags = [row[\"ner_tags\"] for row in train_dict]\n",
    "\n",
    "validation_tokens = [row[\"tokens\"] for row in validation_dict]\n",
    "validation_pos_tags = [row[\"ner_tags\"] for row in validation_dict]\n",
    "validation_ner_tags = [row[\"ner_tags\"] for row in validation_dict]\n",
    "\n",
    "test_tokens = [row[\"tokens\"] for row in test_dict]\n",
    "test_pos_tags = [row[\"ner_tags\"] for row in test_dict]\n",
    "test_ner_tags = [row[\"ner_tags\"] for row in test_dict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lower all characters in a list more simplistically\n",
    "def data_to_lower(data:list[list[str]]) -> list[list[str]]:\n",
    "    return [[token.lower() for token in tokens] for tokens in data]\n",
    "\n",
    "# to easily flatten our data rows into a single list\n",
    "def flatten_list(given_list:list[list[any]]) -> list[any]:\n",
    "    return [element for inner_list in given_list for element in inner_list]\n",
    "\n",
    "# get all unique values in a list, can be used to get also classes\n",
    "def get_unique_tags(tag_list:list[list[str]]) -> list[str]:\n",
    "    return list(set(flatten_list(tag_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case all tokens\n",
    "train_tokens_lower = data_to_lower(train_tokens)\n",
    "validation_tokens_lower = data_to_lower(validation_tokens)\n",
    "test_tokens_lower = data_to_lower(test_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Items and Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Data Item is a row item\n",
    "# holds an optional row index (0 if none given) and a list of tokens\n",
    "# as well as pos and ner tags\n",
    "class DataRow:\n",
    "    def __init__(self, tokens, pos, ner, row_idx=0):\n",
    "        self.idx:int = row_idx\n",
    "        self.tokens:list[str] = tokens\n",
    "        self.pos:list[str] = pos\n",
    "        self.ner:list = ner\n",
    "\n",
    "# The Data collection is the collection of rows\n",
    "# as well as unique IDs and label (NER) embeddings\n",
    "\n",
    "class DataCollection:\n",
    "    def __init__(self, list_collection:list[DataRow], max_token_length=512):\n",
    "        self.max_token_length:int = max_token_length # max token length (if we tokenize inputs)\n",
    "        self.collection:list[DataRow] = list_collection # list of rows in the collection\n",
    "        self.unique_ner_tags:list[str] = []\n",
    "        self.ner_label2idx:dict = {}\n",
    "        self.ner_idx2label:dict = {}\n",
    "        self.ner_as_idx:list[list[int]] = []\n",
    "\n",
    "    # get a list of token rows\n",
    "    def get_token_list(self) -> list[list[str]]:\n",
    "        return [data_item.tokens for data_item in self.collection]\n",
    "\n",
    "    # get a list of pos rows\n",
    "    def get_pos_list(self) -> list[list[str]]:\n",
    "        return [data_item.pos for data_item in self.collection]\n",
    "\n",
    "    # get a list of ner rows\n",
    "    def get_ner_list(self) -> list[list[str]]:\n",
    "        return [data_item.ner for data_item in self.collection]\n",
    "    \n",
    "    # turn the ner str list to integer list (embeddings for tokenisation)\n",
    "    def get_ner_embeddings_list(self, collection:list[DataRow], embeddings:dict) -> list[list[int]]:\n",
    "        ner_idx_list_collection:list[list[int]] = []\n",
    "        for data_item in collection:\n",
    "            ner_idx_list = []\n",
    "            for ner_tag in data_item.ner:\n",
    "                ner_idx_list.append(embeddings[ner_tag])\n",
    "            ner_idx_list_collection.append(ner_idx_list)\n",
    "        return ner_idx_list_collection\n",
    "    \n",
    "    def set_unique_ner_tags(self, tags:list[str]) -> None:\n",
    "        self.unique_ner_tags = tags\n",
    "        self.__set_ner_label2idx__(self.unique_ner_tags)\n",
    "        self.__set_ner_idx2label__(self.ner_label2idx)\n",
    "        self.__set_ner_as_idx__(self.ner_label2idx)\n",
    "\n",
    "    def __set_ner_label2idx__(self, tags:list[str]) -> None:\n",
    "        self.ner_label2idx:dict = {tag:idx for idx, tag in enumerate(tags)}\n",
    "\n",
    "    def __set_ner_idx2label__(self, embeddings:dict) -> None:\n",
    "        self.ner_idx2label:dict = {v:k for k, v in embeddings.items()}\n",
    "    \n",
    "    def __set_ner_as_idx__(self, embeddings:dict) -> None:\n",
    "        self.ner_as_idx:list[list[int]] = self.get_ner_embeddings_list(self.collection, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique label order\n",
    "# IMPORTANT - This should not change\n",
    "# as when the model is trained it uses this for ordering!\n",
    "tag_list = [\"B-O\", \"B-AC\", \"B-LF\", \"I-LF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_collection(token_list:list[list[str]], pos_list:list[list[str]], ner_list:list[list[str]]) -> DataCollection:\n",
    "    data_items:list[DataRow] = []\n",
    "    for idx in range(len(token_list)):\n",
    "        data_items.append(DataRow(token_list[idx], pos_list[idx], ner_list[idx], idx))\n",
    "    collection = DataCollection(data_items)\n",
    "    collection.set_unique_ner_tags(tag_list)\n",
    "    return collection\n",
    "\n",
    "train_collection = data_to_collection(train_tokens_lower, train_pos_tags, train_ner_tags)\n",
    "validation_collection = data_to_collection(validation_tokens_lower, validation_pos_tags, validation_ner_tags)\n",
    "test_collection = data_to_collection(test_tokens_lower, test_pos_tags, test_ner_tags)\n",
    "\n",
    "# set all collections to have the same tag list.\n",
    "# this will avoid metric issues down the line!\n",
    "train_collection.set_unique_ner_tags(tag_list)\n",
    "validation_collection.set_unique_ner_tags(tag_list)\n",
    "test_collection.set_unique_ner_tags(tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BatchEncoding\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_input:BatchEncoding = tokenizer(train_collection.get_token_list()[0], is_split_into_words=True)\n",
    "tokenized_words = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(data_collection:DataCollection) -> BatchEncoding:\n",
    "    tokenized_inputs = tokenizer(data_collection.get_token_list(), truncation=True, is_split_into_words=True, max_length=512) # tokenise inputs\n",
    "\n",
    "    labels = [] # create empty labels list to later matchs with tokenised inputs\n",
    "\n",
    "    for i, label in enumerate(data_collection.ner_as_idx): # enumerate ner tags that we have converted to \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # get word ids\n",
    "        previous_word_idx = None # previous word index to check if same\n",
    "        label_ids = [] # create current label ids list\n",
    "        for word_idx in word_ids:  # for each index\n",
    "            if word_idx is None:  # if index is none must be special token\n",
    "                label_ids.append(-100) # append -100\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx]) # if does not equal previous word idx, append the label\n",
    "            else:\n",
    "                label_ids.append(-100) # if it does, the word has split so we add -100 again\n",
    "            previous_word_idx = word_idx # set the current index as previous index for next check\n",
    "        labels.append(label_ids) # on all processed, add to labels list\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels # add to dictionary, will be input_ids, labels and attention mask\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_list(batch:BatchEncoding):\n",
    "    return [{\"input_ids\": inputs, \"labels\": labels} for labels, inputs in zip(batch[\"labels\"], batch[\"input_ids\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_44296\\2271540387.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [tag_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [tag_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "def get_training_args(\n",
    "        out_dir:str,\n",
    "        learning_rate:float=2e-5,\n",
    "        batch_size:int=16,\n",
    "        epochs:int=2,\n",
    "        weight_decay:float=0.01,\n",
    "        evaluation_strategy:str=\"epoch\",\n",
    "        save_strategy:str=\"epoch\",\n",
    "        lr_scheduler_type=\"linear\") -> TrainingArguments:\n",
    "    return TrainingArguments(\n",
    "        output_dir=out_dir,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        lr_scheduler_type=lr_scheduler_type,\n",
    "        num_train_epochs=epochs, # number of epochs to train, can be overriden by max steps\n",
    "        weight_decay=weight_decay, # The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights\n",
    "        evaluation_strategy=evaluation_strategy, # evaluate at the end of each epoch\n",
    "        save_strategy=save_strategy, # can save by epoch, steps or not at all\n",
    "        save_total_limit=1, # how many checkpoints to keep before overriding (set to 1, so latest checkpoint is only kept)!\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=['none'], # REQUIRED because otherwise keeps asking to log into \"wandb\",\n",
    "        overwrite_output_dir=True,\n",
    "    )\n",
    "\n",
    "def get_trainer(model, training_args:TrainingArguments, tokenised_train:list[dict], tokenised_eval:list[dict]) -> Trainer:\n",
    "    return Trainer(\n",
    "        model=model, # model we use for training\n",
    "        args=training_args, # model arguments\n",
    "        train_dataset=tokenised_train, # train dataset tokenised\n",
    "        eval_dataset=tokenised_eval, # testing dataset tokenised for model training evaluation\n",
    "        tokenizer=tokenizer, # which tokeniser are we using\n",
    "        data_collator=data_collator, # data collector pads the tokens along with the labels\n",
    "        compute_metrics=compute_metrics, # function to compute metrics on how well we are scoring\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_truth_values(given_trainer:Trainer, validation_data_collection:DataCollection, validation_tokenised_list:list[dict], given_label_list):\n",
    "    given_predictions, given_labels, _ = given_trainer.predict(validation_tokenised_list)\n",
    "    true_predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    given_predictions = np.argmax(given_predictions, axis=2)\n",
    "    for prediction, label in zip(given_predictions, given_labels):\n",
    "        for (pred_val, label_val) in zip(prediction, label):\n",
    "            if label_val != -100: # label that is not supposed to be looked at!\n",
    "                true_predictions.append(given_label_list[pred_val])\n",
    "                true_labels.append(given_label_list[label_val])\n",
    "                \n",
    "    return true_predictions, true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trained_model_to_dataframe(trained_model:Trainer, validation_data_collection:DataCollection, validation_tokenised_in:list[dict], label_list_in:dict) -> pd.DataFrame:\n",
    "    truth_predicitons, truth_labels = get_truth_values(trained_model, validation_data_collection, validation_tokenised_in, label_list_in)\n",
    "\n",
    "    df = pd.DataFrame(0, columns=label_list_in, index=label_list_in) # create dataframe with only zeroes but all labels!\n",
    "\n",
    "    for true_label, predict_label in zip(truth_labels, truth_predicitons):\n",
    "        df.at[true_label, predict_label] += 1 # count amount of labels\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_precision(TP, FP) -> float:\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def calc_recall(TP, FN) -> float:\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def calc_f1_score(precision, recall) -> float:\n",
    "    return 2 * ((precision * recall) / (precision + recall))\n",
    "\n",
    "def calculate_metrics(data_frame:pd.DataFrame) -> dict:\n",
    "    metric_dict:dict = {}\n",
    "    df_labels = list(data_frame.index)\n",
    "    for label in list(data_frame.index):\n",
    "        # initialise matrix values to 0\n",
    "        TP:int = 0; TN:int = 0; FP:int = 0; FN:int = 0\n",
    "\n",
    "        # true positive is label itself\n",
    "        TP = data_frame.at[label,label]\n",
    "\n",
    "        # create a copy of all the other labels that is not itself\n",
    "        index_labels = df_labels.copy()\n",
    "        index_labels.remove(label)\n",
    "\n",
    "        # calculate other matrix values\n",
    "        for df_idx in index_labels:\n",
    "            FN += data_frame.at[label,df_idx] # FN is values in the row that is not the current label\n",
    "            FP += data_frame.at[df_idx,label] # FP is values in the column that is not current label\n",
    "            for in_df_idx in index_labels:\n",
    "                # TN is all the other labels that are not in the row and col\n",
    "                # of the dataframe\n",
    "                TN += data_frame.at[df_idx, in_df_idx] \n",
    "\n",
    "        # calculate score per label\n",
    "        prec = calc_precision(TP, FP)\n",
    "        rec = calc_recall(TP, FN)\n",
    "        f1 = calc_f1_score(prec, rec)\n",
    "        metric_dict[label] =  {\n",
    "            \"precision\":prec,\n",
    "            \"recall\":rec,\n",
    "            \"f1_score\":f1\n",
    "        }\n",
    "    return metric_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_dataframe(dataframe:pd.DataFrame, normalised:bool=True) -> ConfusionMatrixDisplay:\n",
    "    if normalised:\n",
    "        result_df = dataframe.div(dataframe.sum(axis=1), axis=0)\n",
    "    else:\n",
    "        result_df = dataframe\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=result_df.to_numpy(), display_labels=list(result_df.index)) \n",
    "    return disp\n",
    "\n",
    "def plot_and_metric(plot_df, normalise=True, name=\"\") -> tuple[ConfusionMatrixDisplay, dict]:\n",
    "    disp = plot_dataframe(plot_df, normalise)\n",
    "    metrics = calculate_metrics(plot_df)\n",
    "    return disp, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_rows_columns(df):\n",
    "    new_labels = {label: label.split('-')[-1] if '-' in label else label for label in df.columns}\n",
    "    new_df = pd.DataFrame(index=list(set(new_labels.values())), columns=list(set(new_labels.values())))\n",
    "\n",
    "    for new_row in new_df.index:\n",
    "        for new_col in new_df.columns:\n",
    "            rows_to_sum = [old_row for old_row, new in new_labels.items() if new == new_row]\n",
    "            cols_to_sum = [old_col for old_col, new in new_labels.items() if new == new_col]\n",
    "            new_df.loc[new_row, new_col] = df.loc[rows_to_sum, cols_to_sum].values.sum()\n",
    "\n",
    "    return new_df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "def get_exp_checkpoint(exp_path:str):\n",
    "    exp_dir:str = os.path.join(working_dir, exp_path)\n",
    "    checkpoint_name:str = os.listdir(exp_dir)[0] # selects first checkpoint name found\n",
    "    return os.path.join(exp_dir, checkpoint_name)\n",
    "\n",
    "def delete_previous_checkpoints(exp_name:str) -> None:\n",
    "    # delete all previous checkpoint to make sure we are not keeping anything if retraining\n",
    "    exp_dir:str = os.path.join(working_dir, exp_name)\n",
    "    if os.path.exists(exp_dir):\n",
    "        checkpoint_name:str = os.listdir(exp_dir)[0]\n",
    "        checkpoint_path:str = os.path.join(exp_dir, checkpoint_name)\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            shutil.rmtree(checkpoint_path)\n",
    "\n",
    "def run_train_and_plot_pipeline(\n",
    "    train_data_collection:DataCollection,\n",
    "    test_data_collection:DataCollection=test_collection,\n",
    "    validation_data_collection:DataCollection=validation_collection,\n",
    "    retrain_model:bool=True,\n",
    "    train_model_checkpoint_name:str=\"distilbert-base-uncased\", # if we re-train use this \n",
    "    exp_path:str=\"exp_test\", # otherwise to load data, will use this\n",
    "    epochs:int=2,\n",
    "    training_args:TrainingArguments=None # override if wanted\n",
    ") -> tuple[ConfusionMatrixDisplay, dict, str, dict]: \n",
    "    label_list:list[str] = train_data_collection.unique_ner_tags\n",
    "    id2label:dict = train_data_collection.ner_idx2label\n",
    "    label2id:dict = train_data_collection.ner_label2idx\n",
    "    if retrain_model:\n",
    "        delete_previous_checkpoints(exp_path)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\n",
    "            train_model_checkpoint_name, \n",
    "            num_labels=len(label_list), \n",
    "            id2label=id2label, \n",
    "            label2id=label2id)\n",
    "    else:\n",
    "        model =  AutoModelForTokenClassification.from_pretrained(\n",
    "            get_exp_checkpoint(exp_path), \n",
    "            num_labels=len(label_list), \n",
    "            id2label=id2label, \n",
    "            label2id=label2id)\n",
    "        \n",
    "    train_tokenised = batch_list(tokenize_and_align_labels(train_data_collection))\n",
    "    test_tokenised = batch_list(tokenize_and_align_labels(test_data_collection))\n",
    "    validation_tokenised = batch_list(tokenize_and_align_labels(validation_data_collection))\n",
    "\n",
    "    training_args = get_training_args(out_dir=exp_path, epochs=epochs) if training_args == None else training_args\n",
    "    trainer:Trainer = get_trainer(\n",
    "        model,\n",
    "        training_args, \n",
    "        train_tokenised, \n",
    "        test_tokenised)\n",
    "    \n",
    "    train_metric = {\n",
    "        \"retrained\":retrain_model,\n",
    "        \"train_time\":\"\",\n",
    "        \"epochs\":epochs\n",
    "    }\n",
    "    if retrain_model:\n",
    "        training_start_time = time.time()\n",
    "        trainer.train()\n",
    "        train_metric[\"train_time\"] = '{:.2f}s'.format(time.time() - training_start_time)\n",
    "        \n",
    "    pipeline_df:pd.DataFrame = trained_model_to_dataframe(trainer, validation_data_collection, validation_tokenised, train_data_collection.unique_ner_tags)\n",
    "    pipeline_df = combine_rows_columns(pipeline_df)\n",
    "    disp, metric_dict = plot_and_metric(pipeline_df, name=exp_path)\n",
    "\n",
    "    return disp, metric_dict, exp_path, train_metric\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Settings!\n",
    "epoch_to_train:int = 50\n",
    "retrain_model = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4513a1668075430ba681f6d5cb7ea8fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db0630d552e442c808554cfc263c4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18310260772705078, 'eval_precision': 0.935179358086847, 'eval_recall': 0.9456936784047518, 'eval_f1': 0.9404071300495728, 'eval_accuracy': 0.9354, 'eval_runtime': 0.2425, 'eval_samples_per_second': 630.814, 'eval_steps_per_second': 41.23, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca18ef91102e4ad68ff052932a92e998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15890218317508698, 'eval_precision': 0.9503410059676044, 'eval_recall': 0.9459058124734833, 'eval_f1': 0.9481182224112269, 'eval_accuracy': 0.943, 'eval_runtime': 0.2027, 'eval_samples_per_second': 754.913, 'eval_steps_per_second': 49.341, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a128bd9c6aa4aae8b6a7437447edafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16473789513111115, 'eval_precision': 0.9523402436418038, 'eval_recall': 0.945269410267289, 'eval_f1': 0.9487916533588843, 'eval_accuracy': 0.9442, 'eval_runtime': 0.1907, 'eval_samples_per_second': 802.171, 'eval_steps_per_second': 52.429, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cecdebe43694df7aa7bff9437202e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15695497393608093, 'eval_precision': 0.9525430942753778, 'eval_recall': 0.9495120916419177, 'eval_f1': 0.9510251779453947, 'eval_accuracy': 0.9464, 'eval_runtime': 0.2007, 'eval_samples_per_second': 762.291, 'eval_steps_per_second': 49.823, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397ffe7b8b504e9d95e269596ea40c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1702721267938614, 'eval_precision': 0.953662182361734, 'eval_recall': 0.9473907509546033, 'eval_f1': 0.9505161221666489, 'eval_accuracy': 0.946, 'eval_runtime': 0.1964, 'eval_samples_per_second': 779.08, 'eval_steps_per_second': 50.92, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b83d5f790e4e49b0502ead46548a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1780245155096054, 'eval_precision': 0.9536423841059603, 'eval_recall': 0.9469664828171405, 'eval_f1': 0.9502927088877062, 'eval_accuracy': 0.9458, 'eval_runtime': 0.203, 'eval_samples_per_second': 753.673, 'eval_steps_per_second': 49.26, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651eb816bfff46a7adb34a0164fd9702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1950204223394394, 'eval_precision': 0.9557219251336898, 'eval_recall': 0.9478150190920662, 'eval_f1': 0.9517520502715944, 'eval_accuracy': 0.9478, 'eval_runtime': 0.2098, 'eval_samples_per_second': 729.221, 'eval_steps_per_second': 47.662, 'epoch': 7.0}\n",
      "{'loss': 0.1584, 'learning_rate': 1.701492537313433e-05, 'epoch': 7.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a783f3e49f1f47b7ac5f30af1044bfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20544955134391785, 'eval_precision': 0.9533844189016603, 'eval_recall': 0.950148493848112, 'eval_f1': 0.9517637059073523, 'eval_accuracy': 0.9472, 'eval_runtime': 0.1907, 'eval_samples_per_second': 802.352, 'eval_steps_per_second': 52.441, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb2ef8d6e9e244df8ffe505cd9b6c7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2155715823173523, 'eval_precision': 0.9539766702014846, 'eval_recall': 0.9541790411540093, 'eval_f1': 0.9540778449464418, 'eval_accuracy': 0.9494, 'eval_runtime': 0.2033, 'eval_samples_per_second': 752.704, 'eval_steps_per_second': 49.196, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90515406192b42bcb77c34e55a2d93e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22702959179878235, 'eval_precision': 0.9495315161839863, 'eval_recall': 0.9459058124734833, 'eval_f1': 0.9477151965993624, 'eval_accuracy': 0.9436, 'eval_runtime': 0.2012, 'eval_samples_per_second': 760.352, 'eval_steps_per_second': 49.696, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f354d157764de18180eda89c4dcebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23576220870018005, 'eval_precision': 0.9542832728049562, 'eval_recall': 0.9476028850233348, 'eval_f1': 0.9509313464608834, 'eval_accuracy': 0.9464, 'eval_runtime': 0.2, 'eval_samples_per_second': 765.034, 'eval_steps_per_second': 50.002, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee00bb8a2ed64e53a7600e125d96ffc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2503521144390106, 'eval_precision': 0.9530685920577617, 'eval_recall': 0.9520577004666949, 'eval_f1': 0.9525628780643106, 'eval_accuracy': 0.9478, 'eval_runtime': 0.2035, 'eval_samples_per_second': 751.785, 'eval_steps_per_second': 49.136, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb11c4ff7544516a10f8fc0a8c46058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2583923935890198, 'eval_precision': 0.9537116040955631, 'eval_recall': 0.9484514212982605, 'eval_f1': 0.9510742395235057, 'eval_accuracy': 0.947, 'eval_runtime': 0.1955, 'eval_samples_per_second': 782.802, 'eval_steps_per_second': 51.164, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b939d57f1d4934b60d3f2b93a19fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2647983431816101, 'eval_precision': 0.9490701606086221, 'eval_recall': 0.9526941026728892, 'eval_f1': 0.9508786788058439, 'eval_accuracy': 0.9472, 'eval_runtime': 0.1962, 'eval_samples_per_second': 779.851, 'eval_steps_per_second': 50.971, 'epoch': 14.0}\n",
      "{'loss': 0.0224, 'learning_rate': 1.4029850746268658e-05, 'epoch': 14.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1da8cbf167c480482883594492ceba5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28858834505081177, 'eval_precision': 0.9521895493970806, 'eval_recall': 0.9548154433602036, 'eval_f1': 0.9535006884863891, 'eval_accuracy': 0.948, 'eval_runtime': 0.2108, 'eval_samples_per_second': 725.84, 'eval_steps_per_second': 47.441, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e617c7358b104884a801ce1adaa0acc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2884122133255005, 'eval_precision': 0.9559855411439506, 'eval_recall': 0.9537547730165464, 'eval_f1': 0.9548688541998513, 'eval_accuracy': 0.9506, 'eval_runtime': 0.2015, 'eval_samples_per_second': 759.323, 'eval_steps_per_second': 49.629, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49f8d25be6a41a9a5d67a24d5f4ce75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3035992980003357, 'eval_precision': 0.9524114383269313, 'eval_recall': 0.946754348748409, 'eval_f1': 0.9495744680851064, 'eval_accuracy': 0.9448, 'eval_runtime': 0.2213, 'eval_samples_per_second': 691.37, 'eval_steps_per_second': 45.188, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c33bda803c3455b895c9a3ae79dced9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2921501100063324, 'eval_precision': 0.9534141671984684, 'eval_recall': 0.9507848960543063, 'eval_f1': 0.952097716409984, 'eval_accuracy': 0.9476, 'eval_runtime': 0.2063, 'eval_samples_per_second': 741.682, 'eval_steps_per_second': 48.476, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3a22431e82471a804a54d0784d7e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31535637378692627, 'eval_precision': 0.9549530315969257, 'eval_recall': 0.9488756894357234, 'eval_f1': 0.9519046605660779, 'eval_accuracy': 0.9472, 'eval_runtime': 0.2084, 'eval_samples_per_second': 734.189, 'eval_steps_per_second': 47.986, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe8363167964d97826612ecbd5cccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3079887628555298, 'eval_precision': 0.953656462585034, 'eval_recall': 0.951633432329232, 'eval_f1': 0.95264387343385, 'eval_accuracy': 0.9478, 'eval_runtime': 0.2151, 'eval_samples_per_second': 711.329, 'eval_steps_per_second': 46.492, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f432573489394b4ba2e81cdfe5db4e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3035695254802704, 'eval_precision': 0.9540523292916401, 'eval_recall': 0.9514212982605006, 'eval_f1': 0.9527349973446627, 'eval_accuracy': 0.948, 'eval_runtime': 0.2008, 'eval_samples_per_second': 761.958, 'eval_steps_per_second': 49.801, 'epoch': 21.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae4dfa489c04d3ebc936e00c7fb13db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.311545729637146, 'eval_precision': 0.9541011474713132, 'eval_recall': 0.9524819686041578, 'eval_f1': 0.9532908704883228, 'eval_accuracy': 0.9484, 'eval_runtime': 0.2103, 'eval_samples_per_second': 727.431, 'eval_steps_per_second': 47.544, 'epoch': 22.0}\n",
      "{'loss': 0.0059, 'learning_rate': 1.1044776119402986e-05, 'epoch': 22.39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4179a1a8ac468bb9110097cf67d6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3153226375579834, 'eval_precision': 0.9542261017670853, 'eval_recall': 0.9507848960543063, 'eval_f1': 0.952502390819254, 'eval_accuracy': 0.9478, 'eval_runtime': 0.212, 'eval_samples_per_second': 721.563, 'eval_steps_per_second': 47.161, 'epoch': 23.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e9e275ca6e4d1b864be91847c1fad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.313147634267807, 'eval_precision': 0.9553571428571429, 'eval_recall': 0.9533305048790836, 'eval_f1': 0.9543427479294967, 'eval_accuracy': 0.9496, 'eval_runtime': 0.2316, 'eval_samples_per_second': 660.725, 'eval_steps_per_second': 43.185, 'epoch': 24.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ab27c65cf447698457a8976d8fd1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31679144501686096, 'eval_precision': 0.9549032120825356, 'eval_recall': 0.9522698345354264, 'eval_f1': 0.9535847052575677, 'eval_accuracy': 0.9484, 'eval_runtime': 0.2155, 'eval_samples_per_second': 710.064, 'eval_steps_per_second': 46.409, 'epoch': 25.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187f534e432240ab919daee963c34c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3251962959766388, 'eval_precision': 0.956503198294243, 'eval_recall': 0.951633432329232, 'eval_f1': 0.9540621012335176, 'eval_accuracy': 0.949, 'eval_runtime': 0.2164, 'eval_samples_per_second': 706.951, 'eval_steps_per_second': 46.206, 'epoch': 26.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396936247bb24ae8b89e590db96812c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3283710479736328, 'eval_precision': 0.9550394204133816, 'eval_recall': 0.9507848960543063, 'eval_f1': 0.9529074093759966, 'eval_accuracy': 0.9482, 'eval_runtime': 0.2181, 'eval_samples_per_second': 701.641, 'eval_steps_per_second': 45.859, 'epoch': 27.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abeb2b9065e4c50b50e97984350f11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3291175663471222, 'eval_precision': 0.954265049989364, 'eval_recall': 0.951633432329232, 'eval_f1': 0.952947424322889, 'eval_accuracy': 0.9486, 'eval_runtime': 0.23, 'eval_samples_per_second': 665.346, 'eval_steps_per_second': 43.487, 'epoch': 28.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb91e83d0634e83b78a9401bdc76f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3249143362045288, 'eval_precision': 0.9537547730165464, 'eval_recall': 0.9537547730165464, 'eval_f1': 0.9537547730165464, 'eval_accuracy': 0.9486, 'eval_runtime': 0.2182, 'eval_samples_per_second': 701.088, 'eval_steps_per_second': 45.823, 'epoch': 29.0}\n",
      "{'loss': 0.0031, 'learning_rate': 8.059701492537314e-06, 'epoch': 29.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d4033a84e84597a8d744026c584bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3295745849609375, 'eval_precision': 0.9547770700636943, 'eval_recall': 0.9539669070852779, 'eval_f1': 0.95437181663837, 'eval_accuracy': 0.9494, 'eval_runtime': 0.2148, 'eval_samples_per_second': 712.411, 'eval_steps_per_second': 46.563, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68c2d5a23174612960097aaa257d5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34031638503074646, 'eval_precision': 0.9529687167482443, 'eval_recall': 0.9499363597793806, 'eval_f1': 0.9514501221714651, 'eval_accuracy': 0.9472, 'eval_runtime': 0.2256, 'eval_samples_per_second': 678.155, 'eval_steps_per_second': 44.324, 'epoch': 31.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9791cc01be84d089b834f9958641fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3531687557697296, 'eval_precision': 0.9545842217484009, 'eval_recall': 0.9497242257106492, 'eval_f1': 0.9521480221182476, 'eval_accuracy': 0.9474, 'eval_runtime': 0.2188, 'eval_samples_per_second': 699.421, 'eval_steps_per_second': 45.714, 'epoch': 32.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaaaff0fcda4522a16144704af192ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35065627098083496, 'eval_precision': 0.9534537725823592, 'eval_recall': 0.951633432329232, 'eval_f1': 0.9525427327741798, 'eval_accuracy': 0.9466, 'eval_runtime': 0.2379, 'eval_samples_per_second': 643.174, 'eval_steps_per_second': 42.038, 'epoch': 33.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fc5f13def244aca2322858c6448adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3490392863750458, 'eval_precision': 0.9550106609808102, 'eval_recall': 0.950148493848112, 'eval_f1': 0.9525733730327519, 'eval_accuracy': 0.947, 'eval_runtime': 0.222, 'eval_samples_per_second': 689.108, 'eval_steps_per_second': 45.04, 'epoch': 34.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07724e2d74a49d6bb47a585cbfadcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34184518456459045, 'eval_precision': 0.9563272262462719, 'eval_recall': 0.9522698345354264, 'eval_f1': 0.9542942176870749, 'eval_accuracy': 0.9492, 'eval_runtime': 0.2226, 'eval_samples_per_second': 687.467, 'eval_steps_per_second': 44.932, 'epoch': 35.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2b818e4cc44700b52c90fd5a4d9dfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35368612408638, 'eval_precision': 0.9549434123425155, 'eval_recall': 0.948663555366992, 'eval_f1': 0.951793125465574, 'eval_accuracy': 0.947, 'eval_runtime': 0.2191, 'eval_samples_per_second': 698.38, 'eval_steps_per_second': 45.646, 'epoch': 36.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faf3240a1454ea2929ffe84271612da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3446611762046814, 'eval_precision': 0.9565124706885525, 'eval_recall': 0.9518455663979635, 'eval_f1': 0.9541733120680489, 'eval_accuracy': 0.9486, 'eval_runtime': 0.2282, 'eval_samples_per_second': 670.463, 'eval_steps_per_second': 43.821, 'epoch': 37.0}\n",
      "{'loss': 0.0016, 'learning_rate': 5.074626865671642e-06, 'epoch': 37.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cecbef0f0dae48e8979858a506eb65be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3472658097743988, 'eval_precision': 0.9558917536756872, 'eval_recall': 0.951633432329232, 'eval_f1': 0.9537578399064527, 'eval_accuracy': 0.949, 'eval_runtime': 0.2283, 'eval_samples_per_second': 670.179, 'eval_steps_per_second': 43.803, 'epoch': 38.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb6b6469d2a455087cb6882fdeb34ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34810274839401245, 'eval_precision': 0.9567348678601876, 'eval_recall': 0.9522698345354264, 'eval_f1': 0.9544971294918136, 'eval_accuracy': 0.9494, 'eval_runtime': 0.2176, 'eval_samples_per_second': 703.034, 'eval_steps_per_second': 45.95, 'epoch': 39.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0fc252faf94c9cb02c0203d5f8d46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3485768735408783, 'eval_precision': 0.9575783415050096, 'eval_recall': 0.9529062367416207, 'eval_f1': 0.9552365762892079, 'eval_accuracy': 0.9502, 'eval_runtime': 0.2192, 'eval_samples_per_second': 697.993, 'eval_steps_per_second': 45.62, 'epoch': 40.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b2e650d5bc41fd90cede8edb619914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35209789872169495, 'eval_precision': 0.9567071870334826, 'eval_recall': 0.951633432329232, 'eval_f1': 0.9541635648197383, 'eval_accuracy': 0.9486, 'eval_runtime': 0.2232, 'eval_samples_per_second': 685.589, 'eval_steps_per_second': 44.81, 'epoch': 41.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc59bdd4d52e460ca6d175b123ee3ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3542582094669342, 'eval_precision': 0.9540913921360255, 'eval_recall': 0.9522698345354264, 'eval_f1': 0.953179743072513, 'eval_accuracy': 0.9478, 'eval_runtime': 0.2156, 'eval_samples_per_second': 709.586, 'eval_steps_per_second': 46.378, 'epoch': 42.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657af5af20e043c7822b836e2679d194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3594226837158203, 'eval_precision': 0.9538199616939774, 'eval_recall': 0.9507848960543063, 'eval_f1': 0.9523000106236056, 'eval_accuracy': 0.9472, 'eval_runtime': 0.2249, 'eval_samples_per_second': 680.297, 'eval_steps_per_second': 44.464, 'epoch': 43.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8c07096de44aaa8b2c37b3c2c69317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35702216625213623, 'eval_precision': 0.9554180887372014, 'eval_recall': 0.950148493848112, 'eval_f1': 0.9527760051052968, 'eval_accuracy': 0.9472, 'eval_runtime': 0.225, 'eval_samples_per_second': 680.054, 'eval_steps_per_second': 44.448, 'epoch': 44.0}\n",
      "{'loss': 0.0012, 'learning_rate': 2.08955223880597e-06, 'epoch': 44.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332e81f1ff7d44bd9d9800f7fd67821c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3585200011730194, 'eval_precision': 0.9548167092924126, 'eval_recall': 0.9503606279168434, 'eval_f1': 0.9525834573676377, 'eval_accuracy': 0.947, 'eval_runtime': 0.2221, 'eval_samples_per_second': 689.029, 'eval_steps_per_second': 45.035, 'epoch': 45.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16c6c5c332148fe9b5429725796aaa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3564692437648773, 'eval_precision': 0.9552620366425224, 'eval_recall': 0.9512091641917692, 'eval_f1': 0.9532312925170068, 'eval_accuracy': 0.9476, 'eval_runtime': 0.2219, 'eval_samples_per_second': 689.625, 'eval_steps_per_second': 45.074, 'epoch': 46.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c62fb077f84d8697a0c2d061e0ac4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3562890291213989, 'eval_precision': 0.9546712066397106, 'eval_recall': 0.951633432329232, 'eval_f1': 0.9531498990757463, 'eval_accuracy': 0.948, 'eval_runtime': 0.2257, 'eval_samples_per_second': 677.949, 'eval_steps_per_second': 44.31, 'epoch': 47.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ae8d6124c4413bb210acedad3ac82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35917773842811584, 'eval_precision': 0.9548359608010226, 'eval_recall': 0.9507848960543063, 'eval_f1': 0.9528061224489797, 'eval_accuracy': 0.9472, 'eval_runtime': 0.2232, 'eval_samples_per_second': 685.339, 'eval_steps_per_second': 44.793, 'epoch': 48.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abd93f8a3624a73847e61cd6d033b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3588024973869324, 'eval_precision': 0.9544390036193315, 'eval_recall': 0.9509970301230377, 'eval_f1': 0.952714908086282, 'eval_accuracy': 0.9476, 'eval_runtime': 0.2251, 'eval_samples_per_second': 679.658, 'eval_steps_per_second': 44.422, 'epoch': 49.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e217ebd50674a38993bd32a186f891c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3581068217754364, 'eval_precision': 0.9542066027689031, 'eval_recall': 0.9503606279168434, 'eval_f1': 0.9522797321713253, 'eval_accuracy': 0.9472, 'eval_runtime': 0.2268, 'eval_samples_per_second': 674.46, 'eval_steps_per_second': 44.082, 'epoch': 50.0}\n",
      "{'train_runtime': 225.5762, 'train_samples_per_second': 237.614, 'train_steps_per_second': 14.851, 'train_loss': 0.028842600201492877, 'epoch': 50.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6db63fd912b4280895a81dbe6c147c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2149b76d8d0>,\n",
       " {'O': {'precision': 0.974044360547428,\n",
       "   'recall': 0.9687866697958226,\n",
       "   'f1_score': 0.9714084009883517},\n",
       "  'AC': {'precision': 0.8212927756653993,\n",
       "   'recall': 0.8212927756653993,\n",
       "   'f1_score': 0.8212927756653993},\n",
       "  'LF': {'precision': 0.8136272545090181,\n",
       "   'recall': 0.8529411764705882,\n",
       "   'f1_score': 0.8328205128205128}},\n",
       " 'checkpoints/distilbert-uncased-best',\n",
       " {'retrained': True, 'train_time': '225.77s', 'epochs': 50})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_train_and_plot_pipeline(train_collection, retrain_model=retrain_model, exp_path=\"checkpoints/distilbert-uncased-best\", epochs=epoch_to_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
