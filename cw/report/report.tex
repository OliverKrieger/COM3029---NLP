\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{multicol}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{ {./imgs/} }

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{
    \huge COM3029 - Natural Language Processing \\
    \Large Coursework 1 \\
    Group 6}
\author{
    Oliver Krieger \\
    URN:6664919
}
\date{April 2024}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage

\section{Introduction}

\subsection{Group 6 Members}

\begin{multicols}{2}
\normalsize \begin{enumerate}
  \item Eleanor Lurgio
  \item Oliver Krieger
  \item Seo(Seoeun) Lee
  \item Thiri(Alice) Thu
\end{enumerate}
\end{multicols}

\subsection{Individual Tasks}

\begin{tabular}{ |p{5.1cm}||p{1.2cm}|p{1.1cm}|p{1.2cm}|p{1.1cm}| }
    \hline
    \multicolumn{5}{|c|}{Individual Tasks} \\
    \hline
    Tasks & Eleanor & Oliver & Seoeun & Alice \\
    \hline
    Data Pre-processing &  & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark &  \\
    \hline
    NLP Algorithms &  &  & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark \\
    \hline
    Text Encoding / Transformation &  & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark &  \\
    \hline
    Dataset Splitting & \cellcolor{green!25}\checkmark &  &  & \cellcolor{green!25}\checkmark \\
    \hline
    Loss Functions and Optimisers & \cellcolor{green!25}\checkmark &  &  & \cellcolor{green!25}\checkmark \\
    \hline
    Hyper Parameters & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark &  \\
    \hline
    Pre-trained models & \cellcolor{green!25}\checkmark & \cellcolor{green!25}\checkmark &  & \cellcolor{green!25}\checkmark \\
    \hline
\end{tabular} \\ \\

{\noindent \large \bf My tasks include:}
\begin{enumerate}
  \item Data Pre-processing
  \item Text Encoding / Transformation
  \item Hyper Parameters (Fine Tuning)
  \item Pre-trained models (DistilBERT and SpaCy)
\end{enumerate}

\section{Data Analysis}

\subsection{Loading The Dataset}

For this coursework, we are exploring the PLOD Dataset which is an English-language dataset of abbreviations and their long-forms tagged in text. The data is gathered from research for PLOS journals. The dataset is loaded using the datasets module. This is done within jupyter notebook environment.

\begin{lstlisting}[language=Python, caption=Load Dataset]
# Import dataset import function for hugging face
from datasets import load_dataset, DatasetDict, Dataset

# import the coursework dataset from
dataset_dict:DatasetDict = load_dataset("surrey-nlp/PLOD-CW") 
\end{lstlisting}
 
This creates a dataset dictionary with 3 datasets - train, validation and test. Each dictionary item has dataset definitions of "tokens", "pos tags" and "ner tags". These are represented as lists of lists of strings (list[list[str]]), the sublists being a representation of rows.

\begin{lstlisting}[language=Python, caption=Dataset Features]
DatasetDict({
    train: Dataset({
        features: ['tokens', 'pos_tags', 'ner_tags'],
        num_rows: 1072
    })
    validation: Dataset({
        features: ['tokens', 'pos_tags', 'ner_tags'],
        num_rows: 126
    })
    test: Dataset({
        features: ['tokens', 'pos_tags', 'ner_tags'],
        num_rows: 153
    })
})
\end{lstlisting}

Each of these datasets can be accessed as normal python dictionaries by calling the dataset name followed by the features name. For instance:
\begin{verbatim}
    dataset["train"]["tokens"]
\end{verbatim}

Would return the list of tokens from the train dataset. As the arrays can become slow to iterate it was sensible to load them into data collections where that contain data items. The collections allow for easy access to lists and reusable functionality.

\subsection{Data Samples}

After loading the dataset, we can test to see how many samples we have to train on, as well as what our split between labels are. To begin observing this, we will want to write some helper functions to make it easier to read the data. First we will write a "flatten list" function that will help us take a list of lists and make it into a singular list:
\begin{lstlisting}[language=Python, caption=Flatten List Function]
def flatten_list(given_list:list[list[any]]) -> list[any]:
    return [element for inner_list in given_list for element in inner_list]
\end{lstlisting}

This way we can combine all our rows into one single list and perform calculations on it. Since every token has to have a pos and ner tag to it, we can assume that all lists are of the same size at the end. To more easily access our data and to speed up our queries, we will create our own DataRow and DataCollection items, as to more easily manipulate the data.

\begin{lstlisting}[language=Python, caption=Data Row and Data Collection]
class DataRow:
    def __init__(self, tokens, pos, ner, row_idx=0):
        self.idx:int = row_idx
        self.tokens:list[str] = tokens
        self.pos:list[str] = pos
        self.ner:list = ner

class DataCollection:
    def __init__(self, list_collection:list[DataRow], max_token_length=512):
        self.max_token_length:int = max_token_length # max token length (if we tokenize inputs)
        self.collection:list[DataRow] = list_collection # list of rows in the collection

    # get a list of token rows
    def get_token_list(self) -> list[list[str]]:
        return [data_item.tokens for data_item in self.collection]

    # get a list of pos rows
    def get_pos_list(self) -> list[list[str]]:
        return [data_item.pos for data_item in self.collection]

    # get a list of ner rows
    def get_ner_list(self) -> list[list[str]]:
        return [data_item.ner for data_item in self.collection]
\end{lstlisting}

By getting each of the lists, we discover that the train dataset has 40,000 tokens, and validation and test sets both have 5000 tokens each. This leads us to 50000 total samples, from which 40000 we use to train on and another 5000 to test while training.

\includegraphics[scale=0.8]{token_count}

As we will be training on the train dataset, we will want to know how many of the 40000 tokens are actually unique. To do this, we will build a function to make a dictionary of unique tokens, as well as to get the frequency of each token.

\begin{lstlisting}[language=Python, caption=Getting Token Frequency]
def get_word_frequency(data_list:list[str]) -> dict:
    word_frequency:dict = {"total_tokens":0, "unique_tokens":0, "unique_token_frequency":{}}
    for value in data_list:
        if value not in word_frequency["unique_token_frequency"].keys():
            word_frequency["unique_token_frequency"][value] = 1
            word_frequency["unique_tokens"] += 1
        else:
            word_frequency["unique_token_frequency"][value] += 1
        word_frequency["total_tokens"] += 1
    return word_frequency
\end{lstlisting}

By looking at the unique tokens in the train set, we find that out of the 40000 samples, we actually only have 9133 unique tokens. This number is actually smaller as we will discuss in the pre-processing step, but for now these will be our unique tokens. From the frequency we can also get which are the most common tokens.

\begin{lstlisting}[language=Python, caption=Getting Token Frequency]
train_frequency:dict = get_word_frequency(flatten_list(train_collection.get_token_list()))
sorted_list = sorted(train_frequency["unique_token_frequency"].items(), key=lambda t: t[1], reverse=True)
sorted_list = sorted_list[:10]
sorted_dict = {item_tuple[0]:item_tuple[1] for item_tuple in sorted_list}
plt.bar(sorted_dict.keys(), sorted_dict.values(), color=colors)
plt.show() # frequency of classes / labels
\end{lstlisting}

\includegraphics[scale=0.8]{top_10_most_frequent}

From plotting the top 10 most frequent tokens, we can clearly see that the most common tokens are stopwords. In order to both balance our classes and focus learning only on abbreviations and long forms, we might benefit from removing them, though we also want to learn what are words that should be labelled as neither, so we will experiment with both.

Next we will want to test how many labels we have available. To do this, we can get use the word frequency function we have already written. This will show us a distribution on the training set of 'B-O': 32971, 'B-LF': 1462, 'I-LF': 3231, 'B-AC': 2336. In a plot it would look as following:

\includegraphics[scale=0.8]{class_distribution}

We can see that we have 4 classes, B-O standing for not an abbreviation or long form, B-AC being an abbreviation, B-LF is long form beginning and I-LF is the continuation of the long form. All long forms will be represented as starting with B-LF followed by I-LF if any. This creates a sequence.

From the plot, we can see that the dataset is imbalanced towards the B-O class. Data imbalance is usually resolved by either oversampling or undersampling the dataset. In the case of oversampling, we would add more values, either from the test or validation set (while removing them from their corresponding set) and adding them to the training set to increase the values of the B-LF, I-LF and B-AC classes. For undersampling we would remove values of B-O. This would be most easily done by removing stop words and their corresponding POS and NER tag values.

\newpage

\section{Experiments}

\subsection{Experiment 1}
\subsubsection{Method}
Experimentation with four different experimental setups, where you might be trying out
different options such as (listing more than four different experiments here, so choose four).
Your PDF report should have a subheading for each of the 4 experiments, numbered 2.1, 2.2,
2.3, and 2.4.
\subsubsection{Analysis}
Analyse testing for each of the four experiment variations conducted above (this refers to
accuracy testing, not software testing) – show visuals, such as confusion matrix or other
relevant metrics for each experiment. Use F1-score as primary evaluation metric. Perform an
error analysis on the predictions obtained. Your PDF report should have a subheading for
each of the 4 experiment variations, numbered 3.1, 3.2, 3.3, and 3.4. (20 marks, 5 marks per
variation)

\subsection{Experiment 2}
\subsection{Experiment 3}
\subsection{Experiment 4}

\section{Conclusion}
\subsection{Experiment Result}
Discuss best and worst results from the testing, on all the experiments you conducted and
mention if there was any need to adjust any variables and re-run the experiment (8 marks, 2
mark per variation)

\subsection{Outcome}
Evaluate the overall attempt and outcome – this goes beyond the accuracy of the models, so
some important questions to consider here are:
a. “Can the models you built fulfil their purpose?”
b. “What is good enough F1/accuracy?”
c. If any of the models did not perform well, what is needed to improve?
d. If any of the models performed really well, could/would you make it more efficient
and sacrifice some quality?


\end{document}
