{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset # Import dataset import function for hugging face\n",
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\") # import the coursework dataset from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dataset[\"train\"][0:200]\n",
    "train_tokens = train_dict[\"tokens\"]\n",
    "train_pos_tags = train_dict[\"pos_tags\"]\n",
    "train_ner_tags = train_dict[\"ner_tags\"]\n",
    "\n",
    "validation_dict = dataset[\"validation\"]\n",
    "validation_tokens = validation_dict[\"tokens\"]\n",
    "validation_pos_tags = validation_dict[\"pos_tags\"]\n",
    "validation_ner_tags = validation_dict[\"ner_tags\"]\n",
    "\n",
    "test_dict = dataset[\"test\"]\n",
    "test_tokens = test_dict[\"tokens\"]\n",
    "test_pos_tags = test_dict[\"pos_tags\"]\n",
    "test_ner_tags = test_dict[\"ner_tags\"]\n",
    "\n",
    "def data_to_lower(data:list[list[str]]) -> list[list[str]]:\n",
    "    return [[token.lower() for token in tokens] for tokens in data]\n",
    "\n",
    "\n",
    "train_tokens = data_to_lower(train_tokens)\n",
    "validation_tokens = data_to_lower(validation_tokens)\n",
    "test_tokens = data_to_lower(test_tokens)\n",
    "\n",
    "class DataItem:\n",
    "    def __init__(self, tokens, pos, ner):\n",
    "        self.tokens:list[str] = tokens\n",
    "        self.pos:list[str] = pos\n",
    "        self.ner:list = ner\n",
    "\n",
    "    def get_as_tuple(self) -> tuple:\n",
    "        return (self.tokens, self.pos, self.ner)\n",
    "    \n",
    "    def get_as_tuple_list(self) -> list[tuple]:\n",
    "        tuple_list = []\n",
    "        for idx in range(len(self.tokens)-1):\n",
    "            tuple_list.append((self.tokens[idx], self.pos[idx], self.ner[idx]))\n",
    "        return tuple_list\n",
    "    \n",
    "    def ner_label2idx(self, label2idx_dict):\n",
    "        if not isinstance(self.ner[0], str):\n",
    "            print(\"WARNING - NER not listed as labels! NER Type: \",type(self.ner[0]),\", Exiting...\")\n",
    "            return\n",
    "        for idx, ner in enumerate(self.ner):\n",
    "            ner[idx] = label2idx_dict[ner]\n",
    "    \n",
    "    def ner_idx2label(self, idx2label_dict):\n",
    "        if not isinstance(self.ner[0], int):\n",
    "            print(\"WARNING - NER not listed as indecies! Exiting...\")\n",
    "            return\n",
    "        for idx, ner in enumerate(self.ner):\n",
    "            ner[idx] = idx2label_dict[ner]\n",
    "\n",
    "class DataCollection:\n",
    "    def __init__(self, data_collection:list[DataItem]):\n",
    "        self.data_collection:list[DataItem] = data_collection\n",
    "        self.unique_tags = self.get_unique_tags()\n",
    "        self.item_embeddings:dict = self.create_item_embeddings(self.unique_tags)\n",
    "        self.reverse_embeddings:dict = {v:k for k,v in self.item_embeddings.items()}\n",
    "\n",
    "    def get_token_list(self) -> list[list[str]]:\n",
    "        return [data_item.tokens for data_item in self.data_collection]\n",
    "\n",
    "    def get_pos_list(self) -> list[list[str]]:\n",
    "        return [data_item.pos for data_item in self.data_collection]\n",
    "\n",
    "    def get_ner_list(self) -> list[list[str]]:\n",
    "        return [data_item.ner for data_item in self.data_collection]\n",
    "    \n",
    "    def get_ner_idx_list(self) -> list[list[str]]:\n",
    "        ner_idx_list_collection = []\n",
    "        for data_item in self.data_collection:\n",
    "            ner_idx_list = []\n",
    "            for ner_tag in data_item.ner:\n",
    "                ner_idx_list.append(self.item_embeddings[ner_tag])\n",
    "            ner_idx_list_collection.append(ner_idx_list)\n",
    "        return ner_idx_list_collection\n",
    "\n",
    "    def get_unique_tags(self) -> list[str]:\n",
    "        unique_list = []\n",
    "        ner_tags_list:list = self.get_ner_list()\n",
    "        for ner_list in ner_tags_list:\n",
    "            for ner in ner_list:\n",
    "                if ner not in unique_list:\n",
    "                    unique_list.append(ner)\n",
    "        return unique_list\n",
    "    \n",
    "    def create_item_embeddings(self, tags:list[str]) -> dict:\n",
    "        return {label:idx for idx, label in enumerate(tags)}\n",
    "\n",
    "train_data:list[DataItem] = []\n",
    "for idx in range(len(train_tokens)):\n",
    "    train_data.append(DataItem(train_tokens[idx], train_pos_tags[idx], train_ner_tags[idx]))\n",
    "train_collection:DataCollection = DataCollection(train_data)\n",
    "\n",
    "validation_data:list[DataItem] = []\n",
    "for idx in range(len(validation_tokens)):\n",
    "    train_data.append(DataItem(validation_tokens[idx], validation_pos_tags[idx], validation_ner_tags[idx]))\n",
    "validation_collection:DataCollection = DataCollection(validation_data)\n",
    "\n",
    "test_data:list[DataItem] = []\n",
    "for idx in range(len(test_tokens)):\n",
    "    train_data.append(DataItem(test_tokens[idx], test_pos_tags[idx], test_ner_tags[idx]))\n",
    "test_collection:DataCollection = DataCollection(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://huggingface.co/docs/transformers/main/en/tasks/token_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create label2id functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B-LF': 0, 'I-LF': 1, 'B-AC': 2, 'B-O': 3}\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n",
      "B-LF\t0\t\n",
      "I-LF\t1\t\n",
      "I-LF\t1\t\n",
      "I-LF\t1\t\n",
      "I-LF\t1\t\n",
      "B-O\t3\t\n",
      "B-AC\t2\t\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n",
      "B-O\t3\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['B-O',\n",
       " 'B-O',\n",
       " 'B-O',\n",
       " 'B-O',\n",
       " 'B-LF',\n",
       " 'I-LF',\n",
       " 'I-LF',\n",
       " 'I-LF',\n",
       " 'I-LF',\n",
       " 'B-O',\n",
       " 'B-AC',\n",
       " 'B-O',\n",
       " 'B-O',\n",
       " 'B-O',\n",
       " 'B-O']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def print_lists_side_by_side(a_list, b_list):\n",
    "    for i in range(max(len(b_list), len(a_list))):\n",
    "        try:\n",
    "            print(f\"{a_list[i]}\\t\", end=\"\")\n",
    "        except IndexError:\n",
    "            print(f\" \\t\", end=\"\")\n",
    "        try:\n",
    "            print(f\"{b_list[i]}\\t\")\n",
    "        except IndexError:\n",
    "            print(f\" \\t\")\n",
    "\n",
    "def get_unique_labels(data:list[DataItem]) -> list[str]:\n",
    "    return list(set([ner for item in data for ner in item.ner]))\n",
    "    # return [\n",
    "    #     ner # returned item to list\n",
    "    #     for item in data # original list to item\n",
    "    #     for ner in item.ner # inner list to out list\n",
    "    # ]\n",
    "\n",
    "unique_labels = get_unique_labels(train_data)\n",
    "\n",
    "def create_label_index(labels:list) -> dict:\n",
    "    return {label:idx for idx, label in enumerate(labels)}\n",
    "\n",
    "label_index = create_label_index(unique_labels)\n",
    "label_index\n",
    "\n",
    "def labels2ids(labels:list[str], label_index:dict) -> list[int]:\n",
    "    id_list:list[int] = []\n",
    "    for label in labels:\n",
    "        if label in label_index.keys():\n",
    "            id_list.append(label_index[label])\n",
    "        else:\n",
    "            id_list.append(None)\n",
    "    return id_list\n",
    "\n",
    "def ids2labels(ids:list[int], label_index:dict) -> list[str]:\n",
    "    label_list:list[int] = []\n",
    "    for id in ids:\n",
    "        label_list.append(list(label_index.keys())[list(label_index.values()).index(id)])\n",
    "    return label_list\n",
    "\n",
    "print(label_index)\n",
    "ner_tags_test = train_data[0].ner\n",
    "ner_to_ids_test = labels2ids(train_data[0].ner, label_index)\n",
    "print_lists_side_by_side(ner_tags_test, ner_to_ids_test)\n",
    "ids_to_ner_test = ids2labels(ner_to_ids_test, label_index)\n",
    "ids_to_ner_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DistilBERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Example\n",
    "\n",
    "Adds extra start and end tags (CLS and SEP), as well potentially splits one word into 2. Thus have to realign indecies.\n",
    "\n",
    "We also have to assign -100 to CLS and SEP so they are ignored by PyTorch loss function (CrossEntropyLoss)\n",
    "\n",
    "Only label first token of a word, add -100 for subtokens of the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'for',\n",
       " 'this',\n",
       " 'purpose',\n",
       " 'the',\n",
       " 'gothenburg',\n",
       " 'young',\n",
       " 'persons',\n",
       " 'empowerment',\n",
       " 'scale',\n",
       " '(',\n",
       " 'g',\n",
       " '##ype',\n",
       " '##s',\n",
       " ')',\n",
       " 'was',\n",
       " 'developed',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(data_collection:DataCollection):\n",
    "    tokenized_inputs = tokenizer(data_collection.get_token_list(), truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(data_collection.get_ner_idx_list()):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = tokenize_and_align_labels(train_collection)\n",
    "tokenized_validation = tokenize_and_align_labels(validation_collection)\n",
    "tokenized_test = tokenize_and_align_labels(test_collection)\n",
    "\n",
    "# def tokenize_and_align_labels(data_dict:dict):\n",
    "#     print(data_dict[\"ner_tags\"])\n",
    "#     tokenized_inputs = tokenizer(data_dict[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "#     labels = []\n",
    "#     for i, label in enumerate(data_dict[f\"ner_tags\"]):\n",
    "#         word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "#         previous_word_idx = None\n",
    "#         label_ids = []\n",
    "#         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "#             if word_idx is None:\n",
    "#                 label_ids.append(-100)\n",
    "#             elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "#                 label_ids.append(label[word_idx])\n",
    "#             else:\n",
    "#                 label_ids.append(-100)\n",
    "#             previous_word_idx = word_idx\n",
    "#         labels.append(label_ids)\n",
    "\n",
    "#     tokenized_inputs[\"labels\"] = labels\n",
    "#     return tokenized_inputs\n",
    "\n",
    "# tokenized_train = train_dict.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_list = train_collection.unique_tags\n",
    "labels = train_collection.unique_tags\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "id2label = train_collection.reverse_embeddings\n",
    "label2id = train_collection.item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=len(labels), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_dict_to_list_of_dict(d):\n",
    "    new_list = []\n",
    "\n",
    "    for labels, inputs in zip(d[\"labels\"], d[\"input_ids\"]):\n",
    "        entry = {\"input_ids\": inputs, \"labels\": labels}\n",
    "        new_list.append(entry)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "tokenised_train = turn_dict_to_list_of_dict(tokenized_train)\n",
    "tokenised_val = turn_dict_to_list_of_dict(tokenized_validation)\n",
    "tokenised_test = turn_dict_to_list_of_dict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d14b1ff6bd144338805498348d8f2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 24\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert_model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;66;03m# REQUIRED because otherwise keeps asking to log into \"wandb\"\u001b[39;00m\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     15\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     16\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     22\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m-> 1929\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[0;32m   1933\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[1;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2266\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[0;32m   2267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2268\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3019\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3016\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   3018\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3019\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3029\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3208\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3205\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   3207\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 3208\u001b[0m loss, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3209\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3210\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3378\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   3348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_step\u001b[39m(\n\u001b[0;32m   3349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3350\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3353\u001b[0m     ignore_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m   3355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3356\u001b[0m \u001b[38;5;124;03m    Perform an evaluation step on `model` using `inputs`.\u001b[39;00m\n\u001b[0;32m   3357\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3376\u001b[0m \u001b[38;5;124;03m        logits and labels (each being optional).\u001b[39;00m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3378\u001b[0m     has_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3379\u001b[0m     \u001b[38;5;66;03m# For CLIP-like models capable of returning loss values.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m     \u001b[38;5;66;03m# If `return_loss` is not specified or being `None` in `inputs`, we check if the default value of `return_loss`\u001b[39;00m\n\u001b[0;32m   3381\u001b[0m     \u001b[38;5;66;03m# is `True` in `model.forward`.\u001b[39;00m\n\u001b[0;32m   3382\u001b[0m     return_loss \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3378\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction_step\u001b[39m(\n\u001b[0;32m   3349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3350\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3353\u001b[0m     ignore_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3354\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[torch\u001b[38;5;241m.\u001b[39mTensor], Optional[torch\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m   3355\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3356\u001b[0m \u001b[38;5;124;03m    Perform an evaluation step on `model` using `inputs`.\u001b[39;00m\n\u001b[0;32m   3357\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3376\u001b[0m \u001b[38;5;124;03m        logits and labels (each being optional).\u001b[39;00m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3378\u001b[0m     has_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_names) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(k) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_names)\n\u001b[0;32m   3379\u001b[0m     \u001b[38;5;66;03m# For CLIP-like models capable of returning loss values.\u001b[39;00m\n\u001b[0;32m   3380\u001b[0m     \u001b[38;5;66;03m# If `return_loss` is not specified or being `None` in `inputs`, we check if the default value of `return_loss`\u001b[39;00m\n\u001b[0;32m   3381\u001b[0m     \u001b[38;5;66;03m# is `True` in `model.forward`.\u001b[39;00m\n\u001b[0;32m   3382\u001b[0m     return_loss \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"distilbert_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=['none'], # REQUIRED because otherwise keeps asking to log into \"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_train,\n",
    "    eval_dataset=tokenised_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
