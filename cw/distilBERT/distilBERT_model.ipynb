{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\olive\\AppData\\Local\\Temp\\ipykernel_54820\\2897015339.py:11: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n",
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric # Import dataset import function for hugging face\n",
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\") # import the coursework dataset from\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification, pipeline\n",
    "from transformers import BatchEncoding\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "import evaluate\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(', 'EGF', ',', 'epidermal', 'growth', 'factor', ';', 'TGF', ',', 'transforming', 'growth', 'factor', ';', 'BTC', ',', 'betacellulin', ';', 'HB', '-', 'EGF', ',', 'heparin', '-', 'binding', 'epidermal', 'growth', 'factor', '(', 'EGF)-like', 'growth', 'factor', ';', 'EREG', ',', 'epiregulin', ';', 'NRG1', ',', 'neuregulin-1', ';', 'NRG2', ',', 'neuregulin-2', ';', 'NRG3', ',', 'neuregulin-3', ';', 'NRG4', ',', 'neuregulin-4', ';', 'PLCÎ³', ',', 'phospholipase', 'C', 'type', 'gamma', ';', 'CAMK2B', ',', 'calcium', '/', 'calmodulin', 'dependent', 'protein', 'kinase', ';', 'PRKCB', ',', 'Protein', 'kinase', 'C', '-', 'beta', ';', 'STAT5', ',', 'Signal', 'transducer', 'and', 'activator', 'of', 'transcription', '5', ';', 'src', ',', 'Rous', 'sarcoma', 'virus', 'gene', ';', 'CRK', ',', 'C', 'T10', 'regulator', 'of', 'a', 'tyrosine', 'kinase', ';', 'NCL', ',', 'NCK', 'Adaptor', 'Protein', '2', ';', 'PTK2', ',', 'PTK2', 'protein', 'tyrosine', 'kinase', '2', ';', 'ABL2', ',', 'V', '-', 'Abl', 'Abelson', 'Murine', 'Leukemia', 'Viral', 'Oncogene', 'Homolog', '2', ';', 'PAK2', ',', 'P21', '(', 'RAC1', ')', 'Activated', 'Kinase', '2', ';', 'MAP2K4', ',', 'Mitogen', '-', 'Activated', 'Protein', 'Kinase', 'Kinase', '4', ';', 'MAPK10', ',', 'Mitogen', '-', 'Activated', 'Protein', 'Kinase', '10', ';', 'SOS1', ',', 'SOS', 'Ras', '/', 'Rac', 'Guanine', 'Nucleotide', 'Exchange', 'Factor', '1', ';', 'Grb2', ',', 'Growth', 'Factor', 'Receptor', 'Bound', 'Protein', '2', ';', 'SHC4', ',', 'Src', 'Homology', '2', 'Domain', '-', 'Containing', '-', 'Transforming', 'Protein', 'C4', ';', 'PIK3C4', ',', 'Phosphatidylinositol-4,5', '-', 'Bisphosphate', '3', '-', 'Kinase', 'Catalytic', 'Subunit', ';', 'AKT3', ',', 'KT', 'Serine', '/', 'Threonine', 'Kinase', '3', ';', 'mTOR', ',', 'Mechanistic', 'Target', 'Of', 'Rapamycin', 'Kinase', ';', 'BCL2', ',', 'BCL2', 'Associated', 'Agonist', 'Of', 'Cell', 'Death', ';', 'GSK3B', ',', 'Glycogen', 'Synthase', 'Kinase', '3', 'Beta', ';', 'CDKN1A', ',', 'Cyclin', 'Dependent', 'Kinase', 'Inhibitor', '1A', ';', 'EIF4EBP1', ',', 'Eukaryotic', 'Translation', 'Initiation', 'Factor', '4E', 'Binding', 'Protein', '1', ';', 'BRAF', ',', 'B', '-', 'Raf', 'Proto', '-', 'Oncogene', ',', 'Serine', '/', 'Threonine', 'Kinase', ';', 'RPS6KB1', ',', 'Ribosomal', 'Protein', 'S6', 'Kinase', 'B1', ';', 'KRAS', ',', 'KRAS', 'Proto', '-', 'Oncogene', ',', 'GTPase', ';', 'JUN', ',', 'Jun', 'Proto', '-', 'Oncogene', ',', 'AP-1', 'Transcription', 'Factor', 'Subunit', ';', 'ELK', ',', 'ETS', 'Transcription', 'Factor', ';', 'Myc', ',', 'MYC', 'Proto', '-', 'Oncogene', ',', 'BHLH', 'Transcription', 'Factor', ';', 'ER', ',', 'endoplasmic', 'reticulum', '.']\n",
      "['[CLS]', '(', 'e', '##gf', ',', 'ep', '##ider', '##mal', 'growth', 'factor', ';', 't', '##gf', ',', 'transforming', 'growth', 'factor', ';', 'bt', '##c', ',', 'beta', '##cel', '##lu', '##lin', ';', 'h', '##b', '-', 'e', '##gf', ',', 'he', '##par', '##in', '-', 'binding', 'ep', '##ider', '##mal', 'growth', 'factor', '(', 'e', '##gf', ')', '-', 'like', 'growth', 'factor', ';', 'er', '##eg', ',', 'ep', '##ire', '##gul', '##in', ';', 'nr', '##g', '##1', ',', 'ne', '##ure', '##gul', '##in', '-', '1', ';', 'nr', '##g', '##2', ',', 'ne', '##ure', '##gul', '##in', '-', '2', ';', 'nr', '##g', '##3', ',', 'ne', '##ure', '##gul', '##in', '-', '3', ';', 'nr', '##g', '##4', ',', 'ne', '##ure', '##gul', '##in', '-', '4', ';', 'plc', '##Î³', ',', 'ph', '##os', '##ph', '##oli', '##pas', '##e', 'c', 'type', 'gamma', ';', 'cam', '##k', '##2', '##b', ',', 'calcium', '/', 'calm', '##od', '##ulin', 'dependent', 'protein', 'kinase', ';', 'pr', '##k', '##cb', ',', 'protein', 'kinase', 'c', '-', 'beta', ';', 'stat', '##5', ',', 'signal', 'trans', '##du', '##cer', 'and', 'act', '##iva', '##tor', 'of', 'transcription', '5', ';', 'sr', '##c', ',', 'ro', '##us', 'sar', '##com', '##a', 'virus', 'gene', ';', 'cr', '##k', ',', 'c', 't', '##10', 'regulator', 'of', 'a', 'ty', '##ros', '##ine', 'kinase', ';', 'nc', '##l', ',', 'nc', '##k', 'adapt', '##or', 'protein', '2', ';', 'pt', '##k', '##2', ',', 'pt', '##k', '##2', 'protein', 'ty', '##ros', '##ine', 'kinase', '2', ';', 'ab', '##l', '##2', ',', 'v', '-', 'ab', '##l', 'abel', '##son', 'mu', '##rine', 'leukemia', 'viral', 'on', '##co', '##gen', '##e', 'homo', '##log', '2', ';', 'pak', '##2', ',', 'p', '##21', '(', 'ra', '##c', '##1', ')', 'activated', 'kinase', '2', ';', 'map', '##2', '##k', '##4', ',', 'mit', '##ogen', '-', 'activated', 'protein', 'kinase', 'kinase', '4', ';', 'map', '##k', '##10', ',', 'mit', '##ogen', '-', 'activated', 'protein', 'kinase', '10', ';', 'so', '##s', '##1', ',', 'so', '##s', 'ras', '/', 'ra', '##c', 'gu', '##ani', '##ne', 'nu', '##cle', '##otide', 'exchange', 'factor', '1', ';', 'gr', '##b', '##2', ',', 'growth', 'factor', 'receptor', 'bound', 'protein', '2', ';', 'sh', '##c', '##4', ',', 'sr', '##c', 'homo', '##logy', '2', 'domain', '-', 'containing', '-', 'transforming', 'protein', 'c', '##4', ';', 'pi', '##k', '##3', '##c', '##4', ',', 'ph', '##os', '##pha', '##ti', '##dy', '##lino', '##sit', '##ol', '-', '4', ',', '5', '-', 'bis', '##ph', '##os', '##phate', '3', '-', 'kinase', 'catalytic', 'subunit', ';', 'ak', '##t', '##3', ',', 'k', '##t', 'ser', '##ine', '/', 'th', '##re', '##oni', '##ne', 'kinase', '3', ';', 'mt', '##or', ',', 'me', '##chan', '##istic', 'target', 'of', 'rap', '##amy', '##cin', 'kinase', ';', 'bc', '##l', '##2', ',', 'bc', '##l', '##2', 'associated', 'ago', '##nist', 'of', 'cell', 'death', ';', 'gs', '##k', '##3', '##b', ',', 'g', '##ly', '##co', '##gen', 'synth', '##ase', 'kinase', '3', 'beta', ';', 'cd', '##k', '##n', '##1', '##a', ',', 'cy', '##cl', '##in', 'dependent', 'kinase', 'inhibitor', '1a', ';', 'e', '##if', '##4', '##eb', '##p', '##1', ',', 'eu', '##kar', '##yo', '##tic', 'translation', 'initiation', 'factor', '4', '##e', 'binding', 'protein', '1', ';', 'bra', '##f', ',', 'b', '-', 'raf', 'proto', '-', 'on', '##co', '##gen', '##e', ',', 'ser', '##ine', '/', 'th', '##re', '##oni', '##ne', 'kinase', ';', 'r', '##ps', '##6', '##k', '##b', '##1', ',', 'rib', '##osomal', 'protein', 's', '##6', 'kinase', 'b1', ';', 'k', '##ras', ',', 'k', '##ras', 'proto', '-', 'on', '##co', '##gen', '##e', ',', 'gt', '##pas', '##e', ';', 'jun', ',', 'jun', 'proto', '-', 'on', '##co', '##gen', '##e', ',', 'ap', '-', '1', 'transcription', 'factor', 'subunit', ';', 'elk', ',', 'et', '##s', 'transcription', 'factor', ';', 'my', '##c', ',', 'my', '##c', 'proto', '-', 'on', '##co', '##gen', '##e', ',', 'b', '##hl', '##h', 'transcription', 'factor', ';', 'er', ',', 'end', '##op', '##las', '##mic', 're', '##tic', '##ulum', '.', '[SEP]']\n",
      "[101, 1006, 1041, 25708, 1010, 4958, 18688, 9067, 3930, 5387, 1025, 1056, 25708, 1010, 17903, 3930, 5387, 1025, 18411, 2278, 1010, 8247, 29109, 7630, 4115, 1025, 1044, 2497, 1011, 1041, 25708, 1010, 2002, 19362, 2378, 1011, 8031, 4958, 18688, 9067, 3930, 5387, 1006, 1041, 25708, 1007, 1011, 2066, 3930, 5387, 1025, 9413, 13910, 1010, 4958, 7442, 24848, 2378, 1025, 17212, 2290, 2487, 1010, 11265, 5397, 24848, 2378, 1011, 1015, 1025, 17212, 2290, 2475, 1010, 11265, 5397, 24848, 2378, 1011, 1016, 1025, 17212, 2290, 2509, 1010, 11265, 5397, 24848, 2378, 1011, 1017, 1025, 17212, 2290, 2549, 1010, 11265, 5397, 24848, 2378, 1011, 1018, 1025, 15492, 29721, 1010, 6887, 2891, 8458, 10893, 19707, 2063, 1039, 2828, 13091, 1025, 11503, 2243, 2475, 2497, 1010, 13853, 1013, 5475, 7716, 18639, 7790, 5250, 21903, 1025, 10975, 2243, 27421, 1010, 5250, 21903, 1039, 1011, 8247, 1025, 28093, 2629, 1010, 4742, 9099, 8566, 17119, 1998, 2552, 11444, 4263, 1997, 14193, 1019, 1025, 5034, 2278, 1010, 20996, 2271, 18906, 9006, 2050, 7865, 4962, 1025, 13675, 2243, 1010, 1039, 1056, 10790, 21618, 1997, 1037, 5939, 7352, 3170, 21903, 1025, 13316, 2140, 1010, 13316, 2243, 15581, 2953, 5250, 1016, 1025, 13866, 2243, 2475, 1010, 13866, 2243, 2475, 5250, 5939, 7352, 3170, 21903, 1016, 1025, 11113, 2140, 2475, 1010, 1058, 1011, 11113, 2140, 16768, 3385, 14163, 11467, 25468, 13434, 2006, 3597, 6914, 2063, 24004, 21197, 1016, 1025, 22190, 2475, 1010, 1052, 17465, 1006, 10958, 2278, 2487, 1007, 8878, 21903, 1016, 1025, 4949, 2475, 2243, 2549, 1010, 10210, 23924, 1011, 8878, 5250, 21903, 21903, 1018, 1025, 4949, 2243, 10790, 1010, 10210, 23924, 1011, 8878, 5250, 21903, 2184, 1025, 2061, 2015, 2487, 1010, 2061, 2015, 20710, 1013, 10958, 2278, 19739, 7088, 2638, 16371, 14321, 26601, 3863, 5387, 1015, 1025, 24665, 2497, 2475, 1010, 3930, 5387, 10769, 5391, 5250, 1016, 1025, 14021, 2278, 2549, 1010, 5034, 2278, 24004, 6483, 1016, 5884, 1011, 4820, 1011, 17903, 5250, 1039, 2549, 1025, 14255, 2243, 2509, 2278, 2549, 1010, 6887, 2891, 21890, 3775, 5149, 25226, 28032, 4747, 1011, 1018, 1010, 1019, 1011, 20377, 8458, 2891, 24556, 1017, 1011, 21903, 26244, 24312, 1025, 17712, 2102, 2509, 1010, 1047, 2102, 14262, 3170, 1013, 16215, 2890, 10698, 2638, 21903, 1017, 1025, 11047, 2953, 1010, 2033, 14856, 6553, 4539, 1997, 9680, 24079, 15459, 21903, 1025, 4647, 2140, 2475, 1010, 4647, 2140, 2475, 3378, 3283, 26942, 1997, 3526, 2331, 1025, 28177, 2243, 2509, 2497, 1010, 1043, 2135, 3597, 6914, 24203, 11022, 21903, 1017, 8247, 1025, 3729, 2243, 2078, 2487, 2050, 1010, 22330, 20464, 2378, 7790, 21903, 24054, 20720, 1025, 1041, 10128, 2549, 15878, 2361, 2487, 1010, 7327, 6673, 7677, 4588, 5449, 17890, 5387, 1018, 2063, 8031, 5250, 1015, 1025, 11655, 2546, 1010, 1038, 1011, 7148, 15053, 1011, 2006, 3597, 6914, 2063, 1010, 14262, 3170, 1013, 16215, 2890, 10698, 2638, 21903, 1025, 1054, 4523, 2575, 2243, 2497, 2487, 1010, 19395, 27642, 5250, 1055, 2575, 21903, 29491, 1025, 1047, 8180, 1010, 1047, 8180, 15053, 1011, 2006, 3597, 6914, 2063, 1010, 14181, 19707, 2063, 1025, 12022, 1010, 12022, 15053, 1011, 2006, 3597, 6914, 2063, 1010, 9706, 1011, 1015, 14193, 5387, 24312, 1025, 18995, 1010, 3802, 2015, 14193, 5387, 1025, 2026, 2278, 1010, 2026, 2278, 15053, 1011, 2006, 3597, 6914, 2063, 1010, 1038, 7317, 2232, 14193, 5387, 1025, 9413, 1010, 2203, 7361, 8523, 7712, 2128, 4588, 25100, 1012, 102]\n",
      "542\n"
     ]
    }
   ],
   "source": [
    "v = dataset[\"train\"][286:287][\"tokens\"][0]\n",
    "input_tokens = tokenizer(v, is_split_into_words=True)\n",
    "input_ids = input_tokens[\"input_ids\"]\n",
    "id_tokens = []\n",
    "for token in input_ids:\n",
    "    id_tokens.append(tokenizer.convert_ids_to_tokens(token))\n",
    "print(v)\n",
    "print(id_tokens)\n",
    "print(input_ids)\n",
    "print(len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dataset[\"train\"]\n",
    "train_tokens = train_dict[\"tokens\"]\n",
    "train_pos_tags = train_dict[\"pos_tags\"]\n",
    "train_ner_tags = train_dict[\"ner_tags\"]\n",
    "\n",
    "validation_dict = dataset[\"validation\"]\n",
    "validation_tokens = validation_dict[\"tokens\"]\n",
    "validation_pos_tags = validation_dict[\"pos_tags\"]\n",
    "validation_ner_tags = validation_dict[\"ner_tags\"]\n",
    "\n",
    "test_dict = dataset[\"test\"]\n",
    "test_tokens = test_dict[\"tokens\"]\n",
    "test_pos_tags = test_dict[\"pos_tags\"]\n",
    "test_ner_tags = test_dict[\"ner_tags\"]\n",
    "\n",
    "def data_to_lower(data:list[list[str]]) -> list[list[str]]:\n",
    "    return [[token.lower() for token in tokens] for tokens in data]\n",
    "\n",
    "train_tokens = data_to_lower(train_tokens)\n",
    "validation_tokens = data_to_lower(validation_tokens)\n",
    "test_tokens = data_to_lower(test_tokens)\n",
    "\n",
    "class DataItem:\n",
    "    def __init__(self, tokens, pos, ner, idx=0):\n",
    "        self.idx=idx\n",
    "        self.tokens:list[str] = tokens\n",
    "        self.pos:list[str] = pos\n",
    "        self.ner:list = ner\n",
    "        self.tokenised_inputs:BatchEncoding = tokenizer(self.tokens, is_split_into_words=True) # also contains attention mask!\n",
    "\n",
    "    def get_as_tuple(self) -> tuple:\n",
    "        return (self.tokens, self.pos, self.ner)\n",
    "    \n",
    "    def get_as_tuple_list(self) -> list[tuple]:\n",
    "        tuple_list = []\n",
    "        for idx in range(len(self.tokens)-1):\n",
    "            tuple_list.append((self.tokens[idx], self.pos[idx], self.ner[idx]))\n",
    "        return tuple_list\n",
    "    \n",
    "    def ner_label2idx(self, label2idx_dict):\n",
    "        if not isinstance(self.ner[0], str):\n",
    "            print(\"WARNING - NER not listed as labels! NER Type: \",type(self.ner[0]),\", Exiting...\")\n",
    "            return\n",
    "        for idx, ner in enumerate(self.ner):\n",
    "            ner[idx] = label2idx_dict[ner]\n",
    "    \n",
    "    def ner_idx2label(self, idx2label_dict):\n",
    "        if not isinstance(self.ner[0], int):\n",
    "            print(\"WARNING - NER not listed as indecies! Exiting...\")\n",
    "            return\n",
    "        for idx, ner in enumerate(self.ner):\n",
    "            ner[idx] = idx2label_dict[ner]\n",
    "\n",
    "class DataCollection:\n",
    "    def __init__(self, data_collection:list[DataItem], max_token_length=512):\n",
    "        self.max_token_length = max_token_length\n",
    "        self.data_collection:list[DataItem] = data_collection\n",
    "        self.unique_tags = self.get_unique_tags()\n",
    "        self.item_embeddings:dict = self.create_item_embeddings(self.unique_tags)\n",
    "        self.reverse_embeddings:dict = {v:k for k,v in self.item_embeddings.items()}\n",
    "\n",
    "    def get_token_list(self) -> list[list[str]]:\n",
    "        return [data_item.tokens for data_item in self.data_collection]\n",
    "\n",
    "    def get_pos_list(self) -> list[list[str]]:\n",
    "        return [data_item.pos for data_item in self.data_collection]\n",
    "\n",
    "    def get_ner_list(self) -> list[list[str]]:\n",
    "        return [data_item.ner for data_item in self.data_collection]\n",
    "    \n",
    "    def get_ner_idx_list(self) -> list[list[str]]:\n",
    "        ner_idx_list_collection = []\n",
    "        for data_item in self.data_collection:\n",
    "            ner_idx_list = []\n",
    "            for ner_tag in data_item.ner:\n",
    "                ner_idx_list.append(self.item_embeddings[ner_tag])\n",
    "            ner_idx_list_collection.append(ner_idx_list)\n",
    "        return ner_idx_list_collection\n",
    "\n",
    "    def get_unique_tags(self) -> list[str]:\n",
    "        unique_list = []\n",
    "        ner_tags_list:list = self.get_ner_list()\n",
    "        for ner_list in ner_tags_list:\n",
    "            for ner in ner_list:\n",
    "                if ner not in unique_list:\n",
    "                    unique_list.append(ner)\n",
    "        return unique_list\n",
    "    \n",
    "    def create_item_embeddings(self, tags:list[str]) -> dict:\n",
    "        return {label:idx for idx, label in enumerate(tags)}\n",
    "    \n",
    "    def get_invalid_token_lengths(self) -> list[int]:\n",
    "        invalid_lengths = []\n",
    "        for idx, data_item in enumerate(self.data_collection):\n",
    "            if len(data_item.tokenised_inputs[\"input_ids\"]) >= self.max_token_length:\n",
    "                invalid_lengths.append(idx)\n",
    "                print(\"Data item idx \",idx,\" has tokens longer than \",self.max_token_length)\n",
    "        return invalid_lengths\n",
    "\n",
    "    def remove_invalid_token_length_items(self) -> None:\n",
    "        invalid_lengths = self.get_invalid_token_lengths()\n",
    "        for index in sorted(invalid_lengths, reverse=True):\n",
    "            del self.data_collection[index]\n",
    "\n",
    "train_data:list[DataItem] = []\n",
    "for idx in range(len(train_tokens)):\n",
    "    train_data.append(DataItem(train_tokens[idx], train_pos_tags[idx], train_ner_tags[idx], idx))\n",
    "train_collection:DataCollection = DataCollection(train_data)\n",
    "\n",
    "validation_data:list[DataItem] = []\n",
    "for idx in range(len(validation_tokens)):\n",
    "    validation_data.append(DataItem(validation_tokens[idx], validation_pos_tags[idx], validation_ner_tags[idx], idx))\n",
    "validation_collection:DataCollection = DataCollection(validation_data)\n",
    "\n",
    "test_data:list[DataItem] = []\n",
    "for idx in range(len(test_tokens)):\n",
    "    test_data.append(DataItem(test_tokens[idx], test_pos_tags[idx], test_ner_tags[idx], idx))\n",
    "test_collection:DataCollection = DataCollection(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data item idx  286  has tokens longer than  512\n"
     ]
    }
   ],
   "source": [
    "train_collection.remove_invalid_token_length_items()\n",
    "validation_collection.remove_invalid_token_length_items()\n",
    "test_collection.remove_invalid_token_length_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://huggingface.co/docs/transformers/main/en/tasks/token_classification\n",
    "\n",
    "# More on https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb#scrollTo=IjyhFKjlEP_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization Example\n",
    "\n",
    "Adds extra start and end tags (CLS and SEP), as well potentially splits one word into 2. Thus have to realign indecies.\n",
    "\n",
    "We also have to assign -100 to CLS and SEP so they are ignored by PyTorch loss function (CrossEntropyLoss)\n",
    "\n",
    "Only label first token of a word, add -100 for subtokens of the same word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'for', 'this', 'purpose', 'the', 'gothenburg', 'young', 'persons', 'empowerment', 'scale', '(', 'g', '##ype', '##s', ')', 'was', 'developed', '.', '[SEP]']\n",
      "{'input_ids': [101, 2005, 2023, 3800, 1996, 22836, 2402, 5381, 23011, 4094, 1006, 1043, 18863, 2015, 1007, 2001, 2764, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)\n",
    "print(tokenized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_align_labels(data_collection:DataCollection):\n",
    "    tokenized_inputs = tokenizer(data_collection.get_token_list(), truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(data_collection.get_ner_idx_list()):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = tokenize_and_align_labels(train_collection)\n",
    "tokenized_validation = tokenize_and_align_labels(validation_collection)\n",
    "tokenized_test = tokenize_and_align_labels(test_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = train_collection.unique_tags\n",
    "labels = train_collection.unique_tags\n",
    "\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "id2label = train_collection.reverse_embeddings\n",
    "label2id = train_collection.item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(labels), id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_dict_to_list_of_dict(d):\n",
    "    new_list = []\n",
    "\n",
    "    for labels, inputs in zip(d[\"labels\"], d[\"input_ids\"]):\n",
    "        entry = {\"input_ids\": inputs, \"labels\": labels}\n",
    "        new_list.append(entry)\n",
    "\n",
    "    return new_list\n",
    "\n",
    "tokenised_train = turn_dict_to_list_of_dict(tokenized_train)\n",
    "tokenised_val = turn_dict_to_list_of_dict(tokenized_validation)\n",
    "tokenised_test = turn_dict_to_list_of_dict(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olive\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b500c65f9d47e39871d8cb3e7fba0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0607c9fdc2641a3ba4fb0a641f01ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory distilbert_model\\checkpoint-67 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5402113795280457, 'eval_precision': 0.8706697459584296, 'eval_recall': 0.8295659131826365, 'eval_f1': 0.849620979307519, 'eval_accuracy': 0.8404, 'eval_runtime': 0.222, 'eval_samples_per_second': 689.299, 'eval_steps_per_second': 45.052, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77261500d7e41caa84a238305b05e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6835944652557373, 'eval_precision': 0.8786975952330283, 'eval_recall': 0.8259651930386077, 'eval_f1': 0.8515157764487524, 'eval_accuracy': 0.8256, 'eval_runtime': 0.1873, 'eval_samples_per_second': 816.698, 'eval_steps_per_second': 53.379, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed26e49a43d740bcb921c25c657d202e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7148677110671997, 'eval_precision': 0.879948914431673, 'eval_recall': 0.8269653930786157, 'eval_f1': 0.8526348355161391, 'eval_accuracy': 0.826, 'eval_runtime': 0.1742, 'eval_samples_per_second': 878.244, 'eval_steps_per_second': 57.402, 'epoch': 3.0}\n",
      "{'train_runtime': 12.4892, 'train_samples_per_second': 257.262, 'train_steps_per_second': 16.094, 'train_loss': 0.30154730194243623, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=201, training_loss=0.30154730194243623, metrics={'train_runtime': 12.4892, 'train_samples_per_second': 257.262, 'train_steps_per_second': 16.094, 'train_loss': 0.30154730194243623, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output_dir = \"distilbert_model\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_output_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3, # number of epochs to train\n",
    "    weight_decay=0.01, # The weight decay to apply (if not zero) to all layers except all bias and LayerNorm weights\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", # can save by epoch, steps or not at all\n",
    "    save_total_limit=1, # how many checkpoints to keep before overriding (set to 1, so latest checkpoint is only kept)!\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=['none'], # REQUIRED because otherwise keeps asking to log into \"wandb\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenised_train,\n",
    "    eval_dataset=tokenised_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001e813c947a494f9041747bf921c3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5402113795280457,\n",
       " 'eval_precision': 0.8706697459584296,\n",
       " 'eval_recall': 0.8295659131826365,\n",
       " 'eval_f1': 0.849620979307519,\n",
       " 'eval_accuracy': 0.8404,\n",
       " 'eval_runtime': 0.4307,\n",
       " 'eval_samples_per_second': 355.262,\n",
       " 'eval_steps_per_second': 23.22,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e4fe4e30f84a4e9811993e091d68d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'AC': {'precision': 0.6996466431095406,\n",
       "  'recall': 0.752851711026616,\n",
       "  'f1': 0.7252747252747251,\n",
       "  'number': 263},\n",
       " 'LF': {'precision': 0.4311377245508982,\n",
       "  'recall': 0.47368421052631576,\n",
       "  'f1': 0.45141065830721,\n",
       "  'number': 152},\n",
       " 'O': {'precision': 0.9566947565543071,\n",
       "  'recall': 0.9591645153719784,\n",
       "  'f1': 0.9579280440642213,\n",
       "  'number': 4261},\n",
       " 'overall_precision': 0.9227022448115205,\n",
       " 'overall_recall': 0.9317792985457656,\n",
       " 'overall_f1': 0.9272185571398169,\n",
       " 'overall_accuracy': 0.9128}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Prepare the test data for evaluation in the same format as the training data\n",
    "\n",
    "# predictions, labels, _ = trainer.predict(tokenised_test)\n",
    "# predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# # label_list = test_collection.get_ner_idx_list()\n",
    "# label_list = train_collection.unique_tags\n",
    "\n",
    "# # Remove the predictions for the [CLS] and [SEP] tokens \n",
    "# true_predictions = [\n",
    "#     [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#     for prediction, label in zip(predictions, labels)\n",
    "# ]\n",
    "# true_labels = [\n",
    "#     [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#     for prediction, label in zip(predictions, labels)\n",
    "# ]\n",
    "\n",
    "# # Compute multiple metrics on the test restuls\n",
    "# results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "# results\n",
    "predictions, labels, _ = trainer.predict(tokenised_val) # tokenized validation used instead of validation dataset (as recommended for vectorised)\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 2, 2, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 3, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "['=', 'manual', 'ability', 'classification', 'system', ';', 'quest', '=', 'quest', '-', 'quality', 'of', 'upper', 'extremity', 'skills', 'test', ';', 'cont', '=', 'control', ';', 'm', '=', 'male', ',', 'f', '=', 'female', ',', 'v', '=', 'verbal', ',', 'nonv', '=', 'non', '-', 'verbal', ',', '|quad', '=', 'quadriplegia', ',', 'di', '=', 'diplegia', ',', 'hemi', '=', 'hemiplegia', '.']\n",
      "67\n",
      "{'input_ids': [101, 1027, 6410, 3754, 5579, 2291, 1025, 8795, 1027, 8795, 1011, 3737, 1997, 3356, 4654, 7913, 16383, 4813, 3231, 1025, 9530, 2102, 1027, 2491, 1025, 1049, 1027, 3287, 1010, 1042, 1027, 2931, 1010, 1058, 1027, 12064, 1010, 2512, 2615, 1027, 2512, 1011, 12064, 1010, 1064, 17718, 1027, 17718, 29443, 23115, 2401, 1010, 4487, 1027, 16510, 23115, 2401, 1010, 19610, 2072, 1027, 19610, 11514, 23115, 2401, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "67\n",
      "['[CLS]', '=', 'manual', 'ability', 'classification', 'system', ';', 'quest', '=', 'quest', '-', 'quality', 'of', 'upper', 'ex', '##tre', '##mity', 'skills', 'test', ';', 'con', '##t', '=', 'control', ';', 'm', '=', 'male', ',', 'f', '=', 'female', ',', 'v', '=', 'verbal', ',', 'non', '##v', '=', 'non', '-', 'verbal', ',', '|', 'quad', '=', 'quad', '##rip', '##leg', '##ia', ',', 'di', '=', 'dip', '##leg', '##ia', ',', 'hem', '##i', '=', 'hem', '##ip', '##leg', '##ia', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "for data_item in validation_collection.data_collection:\n",
    "    t = data_item.tokens\n",
    "    print(len(t))\n",
    "    print(t)\n",
    "    tok = tokenizer(t, is_split_into_words=True)\n",
    "    print(len(tok[\"input_ids\"]))\n",
    "    print(tok) # tokenizer adds the CLS and SEP! So should be safe to rip out first and last character\n",
    "    toks = []\n",
    "    for to in tok[\"input_ids\"]:\n",
    "        toks.append(tokenizer.convert_ids_to_tokens(to))\n",
    "    print(len(toks))\n",
    "    print(toks)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 1, 2, 2, 2, 0, 3, 0, 1, 2, 2, 2, 2, 2, -100, -100, 2, 2, 0, 0, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, 0, 0, 0, 0, 0, 0, -100, 0, 0, -100, -100, -100, 0, 0, 0, 0, -100, -100, 0, 0, -100, 0, 0, -100, -100, -100, 0, -100]\n",
      "['', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-O', 'B-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', '', '', 'I-LF', 'I-LF', 'B-O', 'B-O', '', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', '', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', '', 'B-O', 'B-O', '', '', '', 'B-O', 'B-O', 'B-O', 'B-O', '', '', 'B-O', 'B-O', '', 'B-O', 'B-O', '', '', '', 'B-O', '']\n",
      "67\n"
     ]
    }
   ],
   "source": [
    "id2label[-100] = \"\"\n",
    "validation_labels =  [label for label in tokenized_validation[\"labels\"][0]]\n",
    "print(validation_labels)\n",
    "validation_label_ids = [id2label[label] for label in tokenized_validation[\"labels\"][0]]\n",
    "print(validation_label_ids)\n",
    "print(len(validation_label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentance: electro - oculography ( eog ) ( retiport32 , roland consult , wiesbaden , germany ) was performed in all patients according to the guidelines of the international society for clinical electrophysiology of vision ( iscev).[12 ] arden ratios below 1.8 were rated as pathologic .\n",
      "token length: 46\n",
      "original length: 71\n",
      "['electro', '-', 'o', '##cu', '##log', '##raphy', '(', 'e', '##og', ')', '(', 're', '##tip', '##ort', '##32', ',', 'roland', 'consult', ',', 'wi', '##es', '##bad', '##en', ',', 'germany', ')', 'was', 'performed', 'in', 'all', 'patients', 'according', 'to', 'the', 'guidelines', 'of', 'the', 'international', 'society', 'for', 'clinical', 'electro', '##phy', '##sio', '##logy', 'of', 'vision', '(', 'is', '##ce', '##v', ')', '.', '[', '12', ']', 'arden', 'ratios', 'below', '1', '.', '8', 'were', 'rated', 'as', 'path', '##olo', '##gic', '.']\n",
      "after removing cls and sep length: 69\n",
      "predicted tokens length: 69\n",
      "['I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-LF', 'I-LF', 'B-O', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'I-LF', 'B-O', 'B-AC', 'B-AC', 'B-AC', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O', 'B-O']\n"
     ]
    }
   ],
   "source": [
    "idx_num = 1\n",
    "sentances = []\n",
    "for data_item in validation_collection.data_collection:\n",
    "    sentances.append({\"sentance\":\" \".join(data_item.tokens),\"token_len\":len(data_item.tokens)})\n",
    "print(\"sentance:\", sentances[idx_num][\"sentance\"])\n",
    "print(\"token length:\", sentances[idx_num][\"token_len\"])\n",
    "\n",
    "tokenized_input = [data.tokenised_inputs for data in validation_collection.data_collection]\n",
    "print(\"original length:\", len(tokenized_input[idx_num][\"input_ids\"]))\n",
    "token_values = []\n",
    "for token in tokenized_input[idx_num][\"input_ids\"]:\n",
    "    token_value = tokenizer.convert_ids_to_tokens(token)\n",
    "    if token_value != \"[CLS]\" and token_value != \"[SEP]\":\n",
    "        token_values.append(token_value)\n",
    "print(token_values)\n",
    "print(\"after removing cls and sep length:\", len(token_values))\n",
    "\n",
    "checkpoint_list:list[str] = os.listdir(model_output_dir)\n",
    "last_checkpoint:str = checkpoint_list[-1:][0]\n",
    "last_checkpoint_path:str = os.path.join(model_output_dir, last_checkpoint)\n",
    "classifier = pipeline(\"ner\", model=last_checkpoint_path)\n",
    "result:list[dict] = classifier(sentances[idx_num][\"sentance\"])\n",
    "print(\"predicted tokens length:\",len(result))\n",
    "print([value[\"entity\"] for value in result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentances = []\n",
    "for data_item in validation_collection.data_collection:\n",
    "    sentances.append({\"sentance\":\" \".join(data_item.tokens),\"token_len\":len(data_item.tokens)})\n",
    "\n",
    "measure_dict = []\n",
    "id2label = validation_collection.reverse_embeddings\n",
    "tokenized_validation\n",
    "for idx, tokenised in enumerate(tokenised_val):\n",
    "    # d = {\"tags\":[], \"sentance\":\"\",\"classifier_res\":[]}\n",
    "    tokenised_l = tokenised[\"labels\"][1:-1]\n",
    "    tags = []\n",
    "    prev_id = list(validation_collection.item_embeddings.keys())[0]\n",
    "    for label_id in tokenised_l:\n",
    "        if label_id != -100:\n",
    "            tags.append(id2label[label_id])\n",
    "            prev_id = id2label[label_id]\n",
    "        else:\n",
    "            tags.append(prev_id)\n",
    "    tokenised_in = tokenised[\"input_ids\"][1:-1]\n",
    "    tokens = []\n",
    "    for token in tokenised_in:\n",
    "        tokens.append(tokenizer.convert_ids_to_tokens(token))\n",
    "    result:list[dict] = classifier(sentances[idx][\"sentance\"])\n",
    "    classifier_entities = [value[\"entity\"] for value in result]\n",
    "    measure_dict.append({\"tags\":tags, \"tokens\":tokens, \"sentance\":sentances[idx][\"sentance\"], \"predicted_tags\": classifier_entities})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t -snares syn-1a and snap25 through their interactions with pm - bound voltage - gated calcium channels ( cav ) , l - type in Î² - cells and n - type in neurons , position the predocked sgs to the site of maximum ca2 + influx for efficient exocytosis [ 6â€“12 ] .\n",
      "71\n",
      "71\n"
     ]
    }
   ],
   "source": [
    "idx_val = 3\n",
    "print(measure_dict[idx_val][\"sentance\"])\n",
    "print(len(measure_dict[idx_val][\"tags\"]))\n",
    "print(len(measure_dict[idx_val][\"predicted_tags\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION COLLECTION SIZE:  126\n",
      "TOTAL TOKENS IN VALIDATION SET: 6549\n",
      "TOTAL VALUES: {'B-O': {'correct': 4988, 'incorrect': 220, 'total': 5208}, 'B-LF': {'correct': 27, 'incorrect': 262, 'total': 289}, 'I-LF': {'correct': 355, 'incorrect': 134, 'total': 489}, 'B-AC': {'correct': 313, 'incorrect': 250, 'total': 563}}\n"
     ]
    }
   ],
   "source": [
    "tags = validation_collection.item_embeddings.keys()\n",
    "\n",
    "class TagMetrics:\n",
    "    def __init__(self, tag:str, tag_dict:dict):\n",
    "        self.tag = tag\n",
    "        self.correct = tag_dict[\"correct\"]\n",
    "        self.incorrect = tag_dict[\"incorrect\"]\n",
    "        self.total = tag_dict[\"total\"]\n",
    "\n",
    "class MetricItem:\n",
    "    def __init__(self, total:int, correct:int, incorrect:int, tags_dict:dict, idx=0):\n",
    "        self.idx:int = idx\n",
    "        self.total:int = total\n",
    "        self.correct:int = correct\n",
    "        self.incorrect:int = incorrect\n",
    "        self.tag_metric:list[TagMetrics] = [TagMetrics(tag, tags_dict[tag]) for tag in tags_dict.keys()]\n",
    "\n",
    "class MetricCollection:\n",
    "    def __init__(self, metric_items:list[MetricItem]):\n",
    "        self.data_collection:list[MetricItem] = metric_items\n",
    "        self.total_correct:int = sum([item.correct for item in metric_items]) \n",
    "        self.total_incorrect:int = sum([item.incorrect for item in metric_items])\n",
    "        self.total_label_measurement:dict = self.__items_to_label_measure__()\n",
    "\n",
    "    def __items_to_label_measure__(self) -> dict:\n",
    "        tag_measure = {}\n",
    "        for item in metric_items:\n",
    "            for tag_metric in item.tag_metric:\n",
    "                if tag_metric.tag not in tag_measure.keys():\n",
    "                    tag_measure[tag_metric.tag] = {\"correct\":tag_metric.correct, \"incorrect\":tag_metric.incorrect, \"total\":tag_metric.total}\n",
    "                else:\n",
    "                    tag_measure[tag_metric.tag][\"correct\"] += tag_metric.correct\n",
    "                    tag_measure[tag_metric.tag][\"incorrect\"] += tag_metric.incorrect\n",
    "                    tag_measure[tag_metric.tag][\"total\"] += tag_metric.total\n",
    "        return tag_measure\n",
    "\n",
    "print(\"VALIDATION COLLECTION SIZE: \", len(validation_collection.data_collection))\n",
    "total_tokens = 0\n",
    "for idx in range(len(measure_dict)):\n",
    "    total_tokens += len(measure_dict[idx][\"tokens\"])\n",
    "print(\"TOTAL TOKENS IN VALIDATION SET:\", total_tokens)\n",
    "\n",
    "\n",
    "metric_items:list[MetricItem] = []\n",
    "for idx in range(len(measure_dict)):\n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    tags_dict = {tag:{\"correct\":0, \"incorrect\":0, \"total\":0} for tag in tags}\n",
    "    current_total = len(measure_dict[idx][\"tokens\"])\n",
    "    for d_idx in range(current_total):\n",
    "        tag = measure_dict[idx][\"tags\"][d_idx]\n",
    "        predicted_tag = measure_dict[idx][\"predicted_tags\"][d_idx]\n",
    "        if tag == predicted_tag:\n",
    "            correct += 1\n",
    "            tags_dict[tag][\"correct\"] += 1\n",
    "            tags_dict[tag][\"total\"] += 1\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            tags_dict[tag][\"incorrect\"] += 1\n",
    "            tags_dict[tag][\"total\"] += 1\n",
    "    metric_items.append(MetricItem(current_total, correct, incorrect, tags_dict, idx=idx))\n",
    "    # break # for only 1 item\n",
    "\n",
    "metric_collection:MetricCollection = MetricCollection(metric_items)\n",
    "print(\"TOTAL VALUES:\", metric_collection.total_label_measurement)\n",
    "# print(\"IDX:1\")\n",
    "# print(\"TOTAL CORRECT:\",correct,\"/\",current_total)\n",
    "# print(\"TOTAL INCORRECT:\",incorrect,\"/\",current_total)\n",
    "# for k in tags_dict.keys():\n",
    "#     print(k, \":\", tags_dict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       B-O  B-LF  I-LF  B-AC\n",
      "B-O   4988     7   123    90\n",
      "B-LF   115    27   137    10\n",
      "I-LF   133     0   355     1\n",
      "B-AC   241     0     9   313\n",
      "Precision: 0.652353426919901\n",
      "Recall: 0.6816220880069025\n",
      "F1_Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tags = validation_collection.get_unique_tags()\n",
    "df = pd.DataFrame(0, columns=tags, index=tags)\n",
    "\n",
    "for idx in range(len(measure_dict)):\n",
    "    for d_idx in range(len(measure_dict[idx][\"tokens\"])):\n",
    "        tag = measure_dict[idx][\"tags\"][d_idx]\n",
    "        predicted_tag = measure_dict[idx][\"predicted_tags\"][d_idx]\n",
    "        df.at[tag, predicted_tag] += 1 # first is row, second is column (meaning rows are true tags and columns are predicted tags)\n",
    "print(df) # center diagonally is TP (and TN) and everything else is FP (and FN)!\n",
    "\n",
    "def calc_precision(TP, FP):\n",
    "    return TP / (TP + FP)\n",
    "\n",
    "def calc_recall(TP, FN):\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "def calc_f1(precision, recall):\n",
    "    return (2 * precision * recall) / (precision + recall)\n",
    "\n",
    "total_correct = 0\n",
    "for tag in tags:\n",
    "    total_correct += df.at[tag,tag]\n",
    "\n",
    "total_incorrect = total_tokens - total_correct\n",
    "\n",
    "TP = 56 + 410 + 324\n",
    "TN = 4969\n",
    "FP = 104 + 1 + 7 + 77 + 0 + 232\n",
    "FN = 19 + 126 + 1 + 132 + 3 + 88\n",
    "# precision = calc_precision(total_correct, total_incorrect)\n",
    "# recall = calc_recall(total_correct, total_incorrect)\n",
    "# f1_score = calc_f1(precision, recall)\n",
    "\n",
    "precision = calc_precision(TP, FP)\n",
    "recall = calc_recall(TP, FN)\n",
    "f1_score = calc_f1(precision, recall)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1_Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Predicted Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>=</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>manual</td>\n",
       "      <td>B-LF</td>\n",
       "      <td>B-LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ability</td>\n",
       "      <td>I-LF</td>\n",
       "      <td>I-LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>classification</td>\n",
       "      <td>I-LF</td>\n",
       "      <td>I-LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>system</td>\n",
       "      <td>I-LF</td>\n",
       "      <td>I-LF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hem</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>##ip</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>##leg</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>##ia</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>.</td>\n",
       "      <td>B-O</td>\n",
       "      <td>B-O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tokens  Tags Predicted Tags\n",
       "0                =   B-O            B-O\n",
       "1           manual  B-LF           B-LF\n",
       "2          ability  I-LF           I-LF\n",
       "3   classification  I-LF           I-LF\n",
       "4           system  I-LF           I-LF\n",
       "..             ...   ...            ...\n",
       "60             hem   B-O            B-O\n",
       "61            ##ip   B-O            B-O\n",
       "62           ##leg   B-O            B-O\n",
       "63            ##ia   B-O            B-O\n",
       "64               .   B-O            B-O\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe the first item in validation set!\n",
    "\n",
    "data = []\n",
    "for idx in range(len(measure_dict)):\n",
    "    for d_idx in range(len(measure_dict[idx][\"tokens\"])):\n",
    "        data.append([measure_dict[idx][\"tokens\"][d_idx], measure_dict[idx][\"tags\"][d_idx], measure_dict[idx][\"predicted_tags\"][d_idx]])\n",
    "    break\n",
    "df = pd.DataFrame(data, columns=['Tokens', 'Tags', \"Predicted Tags\"])\n",
    "df.to_csv('result.csv', index=False)  \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
